
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>1. Concept &#8212; CAMEL 0.2.62 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=3c972f42" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=b2b93ad3"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'key_modules/models';</script>
    <link rel="icon" href="https://raw.githubusercontent.com/camel-ai/camel/master/misc/favicon.png"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1. Concept" href="messages.html" />
    <link rel="prev" title="Chain of Thought (CoT) Data Generation" href="datagen.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo_light.png" class="logo__image only-light" alt=""/>
    <script>document.write(`<img src="https://raw.githubusercontent.com/camel-ai/camel/master/misc/logo_light.png" class="logo__image only-dark" alt=""/>`);</script>
  
  
    <p class="title logo__title">CAMEL 0.2.62</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../get_started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get_started/setup.html">API Setup</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Key Modules</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="agents.html">1. Concept</a></li>




<li class="toctree-l1"><a class="reference internal" href="datagen.html">Chain of Thought (CoT) Data Generation</a></li>



<li class="toctree-l1 current active"><a class="current reference internal" href="#">1. Concept</a></li>





<li class="toctree-l1"><a class="reference internal" href="messages.html">1. Concept</a></li>



<li class="toctree-l1"><a class="reference internal" href="memory.html">1. Concept</a></li>





<li class="toctree-l1"><a class="reference internal" href="tools.html">1. Concept</a></li>




<li class="toctree-l1"><a class="reference internal" href="prompts.html">1. Concept</a></li>



<li class="toctree-l1"><a class="reference internal" href="runtimes.html">1. Concept</a></li>




<li class="toctree-l1"><a class="reference internal" href="tasks.html">1. Concept</a></li>




<li class="toctree-l1"><a class="reference internal" href="loaders.html">1. Concept</a></li>


<li class="toctree-l1"><a class="reference internal" href="storages.html">1. Concept</a></li>


<li class="toctree-l1"><a class="reference internal" href="society.html">1. Concept</a></li>



<li class="toctree-l1"><a class="reference internal" href="embeddings.html">1. Concept</a></li>


<li class="toctree-l1"><a class="reference internal" href="retrievers.html">1. Concept</a></li>


<li class="toctree-l1"><a class="reference internal" href="workforce.html">System Design</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Cookbooks</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/basic_concepts/index.html">Basic Concepts</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/basic_concepts/create_your_first_agent.html">Creating Your First Agent</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/basic_concepts/create_your_first_agents_society.html">Creating Your First Agent Society</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/basic_concepts/agents_message.html">Message Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/basic_concepts/agents_prompting.html">Prompting Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/basic_concepts/model_speed_comparison.html">Model Speed Comparison Cookbook</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/advanced_features/index.html">Advanced Features</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_tools.html">Tools Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_tools_from_ACI.html">Using Tools from ACI</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_tools_from_Composio.html">Using Tools from Composio</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_human_in_loop_and_tool_approval.html">Agents with Human-in-loop and Tool Approval from HumanLayer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_memory.html">Memory Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_rag.html">RAG Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_graph_rag.html">Graph RAG Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_with_MCP.html">CAMEL MCP Cookbook</a></li>

<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/agents_tracking.html">Track CAMEL Agents with AgentOps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/critic_agents_and_tree_search.html">Critic Agents and Tree Search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/advanced_features/embodied_agents.html">Embodied Agents</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/multi_agent_society/index.html">Multi-agent Society</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/multi_agent_society/agents_society.html">Develop Trading Bot with Role Playing</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/multi_agent_society/workforce_judge_committee.html">Create A Hackathon Judge Committee with Workforce</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/multi_agent_society/task_generation.html">Task Generation Cookbook</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/data_generation/index.html">Agentic Data Generation</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_mistral_7b_instruct.html">Agentic SFT Data generation with CAMEL and finetuning Mistral models with Unsloth</a></li>

<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_Qwen2_5_7B.html">Agentic Data generation with CAMEL and finetuning Qwen models with Unsloth</a></li>

<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/sft_data_generation_and_unsloth_finetuning_tinyllama.html">Agentic SFT Data generation with CAMEL and finetuning Meta models with Unsloth</a></li>

<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/data_gen_with_real_function_calls_and_hermes_format.html">Real Function Calls and Hermes Format Data Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/self_instruct_data_generation.html">Self-instruct Data Generation Using Qwen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/cot_data_gen_sft_qwen_unsolth_upload_huggingface.html">CoT Data Generation and SFT Qwen With Unsloth</a></li>


<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/synthetic_dataevaluation%26filter_with_reward_model.html">Agentic Data Generation, Evaluation &amp; Filtering with Reward Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/data_model_generation_and_structured_output_with_qwen.html">Agentic Data Model Generation and Structured Output Powered by CAMEL &amp; Qwen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/distill_math_reasoning_data_from_deepseek_r1.html">Distill Math Reasoning Data from DeepSeek R1 with CAMEL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/self_improving_math_reasoning_data_distillation_from_deepSeek_r1.html">Self-Improving Math Reasoning Data Distillation from DeepSeek R1 with CAMEL</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_generation/self_improving_cot_generation.html">Deep Dive into CAMEL‚Äôs Practices for Self-Improving CoT Generation üöÄ</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/applications/index.html">Applications</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/applications/roleplaying_scraper.html">Role-Playing Scraper for Report &amp; Knowledge Graph Generation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/applications/dynamic_travel_planner.html">Dynamic Travel Planner Role-Playing: Multi-Agent System with Real-Time Insights Powered by Dappier</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/applications/customer_service_Discord_bot_with_agentic_RAG.html">Customer Service Discord Bot with Agentic RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/applications/customer_service_Discord_bot_using_SambaNova_with_agentic_RAG.html">Customer Service Discord Bot Using SambaNova with Agentic RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/applications/customer_service_Discord_bot_using_local_model_with_agentic_RAG.html">Customer Service Discord Bot Using Local Models with Agentic RAG</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/applications/finance_discord_bot.html">Customer Service Discord Bot for Finance with OpenBB</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/data_processing/index.html">Data Processing and Analysis</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_processing/video_analysis.html">Video Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_processing/agent_with_chunkr_for_pdf_parsing.html">Create AI Agents that work with your PDFs using Chunkr &amp; Mistral AI</a></li>

<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_processing/summarisation_agent_with_mistral_ocr.html">Create Document Summarization Agents with Mistral OCR &amp; CAMEL-AI üê´</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/data_processing/ingest_data_from_websites_with_Firecrawl.html">3 ways to ingest data from websites with Firecrawl</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/loong/index.html">Loong Cookbooks</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/loong/batched_single_step_env.html">Batched Single Step Environment in Camel</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/loong/multi_step_rl.html">Tic Tac Toe</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/loong/single_step_env.html">Single Step Environment in Camel</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cookbooks/mcp/index.html">MCP Cookbooks</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../cookbooks/mcp/agents_with_sql_mcp.html">CAMEL Cookbook: SQL MCP Server</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">API References</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../modules.html">camel</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../camel.html">camel package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.agents.html">camel.agents package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.agents.tool_agents.html">camel.agents.tool_agents package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.configs.html">camel.configs package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.datagen.html">camel.datagen package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.datagen.self_instruct.html">camel.datagen.self_instruct package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.datagen.source2synth.html">camel.datagen.source2synth package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.embeddings.html">camel.embeddings package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.interpreters.html">camel.interpreters package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.loaders.html">camel.loaders package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.memories.html">camel.memories package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.memories.blocks.html">camel.memories.blocks package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.memories.context_creators.html">camel.memories.context_creators package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.messages.html">camel.messages package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.models.html">camel.models package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.prompts.html">camel.prompts package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.responses.html">camel.responses package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.retrievers.html">camel.retrievers package</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.societies.html">camel.societies package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.societies.workforce.html">camel.societies.workforce package</a></li>
</ul>
</details></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../camel.storages.html">camel.storages package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.graph_storages.html">camel.storages.graph_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.key_value_storages.html">camel.storages.key_value_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.object_storages.html">camel.storages.object_storages package</a></li>
<li class="toctree-l4"><a class="reference internal" href="../camel.storages.vectordb_storages.html">camel.storages.vectordb_storages package</a></li>
</ul>
</details></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.tasks.html">camel.tasks package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.terminators.html">camel.terminators package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.toolkits.html">camel.toolkits package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.types.html">camel.types package</a></li>
<li class="toctree-l3"><a class="reference internal" href="../camel.utils.html">camel.utils package</a></li>
</ul>
</details></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/camel-ai/camel" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/camel-ai/camel/edit/main/key_modules/models.md" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/camel-ai/camel/issues/new?title=Issue%20on%20page%20%2Fkey_modules/models.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/key_modules/models.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>1. Concept</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> On this page </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">1. Concept</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-model-platforms-in-camel">2. Supported Model Platforms in CAMEL</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use-models-via-api-calls">3. How to Use Models via API Calls</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#using-on-device-open-source-models">4. Using On-Device Open Source Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama-to-set-llama-3-locally">4.1 Using Ollama to Set Llama 3 Locally</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-vllm-to-set-phi-3-locally">4.2 Using vLLM to Set Phi-3 Locally</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-sglang-to-set-meta-llama-llama-locally">4.3 Using SGLang to Set meta-llama/Llama Locally</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#model-speed-and-performance">5 Model Speed and Performance</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">6. Next Steps</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="concept">
<h1>1. Concept<a class="headerlink" href="#concept" title="Link to this heading">#</a></h1>
<p>The model is the brain of the intelligent agent, responsible for intelligent agent, processing all input and output data to execute tasks such as text analysis, image recognition, and complex reasoning. With customizable interfaces and multiple integration options, CAMEL AI enables rapid development with leading LLMs.</p>
<blockquote>
<div><p><strong>Explore the Code:</strong> Check out our <a class="reference external" href="https://colab.research.google.com/drive/18hQLpte6WW2Ja3Yfj09NRiVY-6S2MFu7?usp=sharing">Colab Notebook</a> for a hands-on demonstration.</p>
</div></blockquote>
</section>
<section id="supported-model-platforms-in-camel">
<h1>2. Supported Model Platforms in CAMEL<a class="headerlink" href="#supported-model-platforms-in-camel" title="Link to this heading">#</a></h1>
<p>CAMEL supports a wide range of models, including <a class="reference external" href="https://platform.openai.com/docs/models">OpenAI‚Äôs GPT series</a>, <a class="reference external" href="https://www.llama.com/">Meta‚Äôs Llama models</a>, <a class="reference external" href="https://www.deepseek.com/">DeepSeek models</a> (R1 and other variants), and more. The table below lists all supported model platforms:</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Model Platform</p></th>
<th class="head"><p>Model Type(s)</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>OpenAI</strong></p></td>
<td><p>gpt-4.5-preview, gpt-4o, gpt-4o-mini, o1, o1-preview, o1-mini, o3-mini, gpt-4-turbo, gpt-4, gpt-3.5-turbo</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Azure OpenAI</strong></p></td>
<td><p>gpt-4o, gpt-4-turbo, gpt-4, gpt-3.5-turbo</p></td>
</tr>
<tr class="row-even"><td><p><strong>Mistral AI</strong></p></td>
<td><p>mistral-large-latest, pixtral-12b-2409, ministral-8b-latest, ministral-3b-latest, open-mistral-nemo, codestral-latest, open-mistral-7b, open-mixtral-8x7b, open-mixtral-8x22b, open-codestral-mamba</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Moonshot</strong></p></td>
<td><p>moonshot-v1-8k, moonshot-v1-32k, moonshot-v1-128k</p></td>
</tr>
<tr class="row-even"><td><p><strong>Anthropic</strong></p></td>
<td><p>claude-2.1, claude-2.0, claude-instant-1.2, claude-3-opus-latest, claude-3-sonnet-20240229, claude-3-haiku-20240307, claude-3-5-sonnet-latest, claude-3-5-haiku-latest</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Gemini</strong></p></td>
<td><p>gemini-2.5-flash-preview-04-17, gemini-2.5-pro-preview-05-06, gemini-2.0-flash, gemini-2.0-flash-exp, gemini-2.0-flash-thinking-exp, gemini-2.0-pro-exp-02-05, gemini-2.0-flash-lite, gemini-2.0-flash-lite-preview-02-05, gemini-1.5-flash, gemini-1.5-pro</p></td>
</tr>
<tr class="row-even"><td><p><strong>Lingyiwanwu</strong></p></td>
<td><p>yi-lightning, yi-large, yi-medium, yi-large-turbo, yi-vision, yi-medium-200k, yi-spark, yi-large-rag, yi-large-fc</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Qwen</strong></p></td>
<td><p>qwq-32b-preview, qwen-max, qwen-plus, qwen-turbo, qwen-long, qwen-vl-max, qwen-vl-plus, qwen-math-plus, qwen-math-turbo, qwen-coder-turbo, qwen2.5-coder-32b-instruct, qwen2.5-72b-instruct, qwen2.5-32b-instruct, qwen2.5-14b-instruct</p></td>
</tr>
<tr class="row-even"><td><p><strong>DeepSeek</strong></p></td>
<td><p>deepseek-chat, deepseek-reasoner</p></td>
</tr>
<tr class="row-odd"><td><p><strong>ZhipuAI</strong></p></td>
<td><p>glm-4, glm-4v, glm-4v-flash, glm-4v-plus-0111, glm-4-plus, glm-4-air, glm-4-air-0111, glm-4-airx, glm-4-long, glm-4-flashx, glm-zero-preview, glm-4-flash, glm-3-turbo</p></td>
</tr>
<tr class="row-even"><td><p><strong>InternLM</strong></p></td>
<td><p>internlm3-latest, internlm3-8b-instruct, internlm2.5-latest, internlm2-pro-chat</p></td>
</tr>
<tr class="row-odd"><td><p><strong>Reka</strong></p></td>
<td><p>reka-core, reka-flash, reka-edge</p></td>
</tr>
<tr class="row-even"><td><p><strong>COHERE</strong></p></td>
<td><p>command-r-plus, command-r, command-light, command, command-nightly</p></td>
</tr>
<tr class="row-odd"><td><p><strong>GROQ</strong></p></td>
<td><p><a class="reference external" href="https://console.groq.com/docs/models">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>TOGETHER AI</strong></p></td>
<td><p><a class="reference external" href="https://docs.together.ai/docs/chat-models">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>SambaNova</strong></p></td>
<td><p><a class="reference external" href="https://docs.sambanova.ai/cloud/docs/get-started/supported-models">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>Ollama</strong></p></td>
<td><p><a class="reference external" href="https://ollama.com/library">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>OpenRouter</strong></p></td>
<td><p><a class="reference external" href="https://openrouter.ai/models">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>PPIO</strong></p></td>
<td><p><a class="reference external" href="https://ppinfra.com/model-api/product/llm-api?utm_source=github_owl">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>LiteLLM</strong></p></td>
<td><p><a class="reference external" href="https://docs.litellm.ai/docs/providers">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>LMStudio</strong></p></td>
<td><p><a class="reference external" href="https://lmstudio.ai/models">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>vLLM</strong></p></td>
<td><p><a class="reference external" href="https://docs.vllm.ai/en/latest/models/supported_models.html">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>SGLANG</strong></p></td>
<td><p><a class="reference external" href="https://sgl-project.github.io/references/supported_models.html">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>NetMind</strong></p></td>
<td><p><a class="reference external" href="https://www.netmind.ai/modelsLibrary">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>NOVITA</strong></p></td>
<td><p><a class="reference external" href="https://novita.ai/models?utm_source=github_owl&amp;amp;utm_medium=github_readme&amp;amp;utm_campaign=github_link">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>NVIDIA</strong></p></td>
<td><p><a class="reference external" href="https://docs.api.nvidia.com/nim/reference/llm-apis">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>AIML</strong></p></td>
<td><p><a class="reference external" href="https://docs.aimlapi.com/api-overview/model-database/text-models">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>ModelScope</strong></p></td>
<td><p><a class="reference external" href="https://www.modelscope.cn/docs/model-service/API-Inference/intro">supported models</a></p></td>
</tr>
<tr class="row-even"><td><p><strong>AWS Bedrock</strong></p></td>
<td><p><a class="reference external" href="https://us-west-2.console.aws.amazon.com/bedrock/home?region=us-west-2#/">supported models</a></p></td>
</tr>
<tr class="row-odd"><td><p><strong>IBM WatsonX</strong></p></td>
<td><p><a class="reference external" href="https://jp-tok.dataplatform.cloud.ibm.com/samples?context=wx&amp;amp;tab=foundation-model">supported models</a></p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="how-to-use-models-via-api-calls">
<h1>3. How to Use Models via API Calls<a class="headerlink" href="#how-to-use-models-via-api-calls" title="Link to this heading">#</a></h1>
<p>Easily integrate your chosen model with CAMEL AI using straightforward API calls. For example, to use the <strong>gpt-4o-mini</strong> model:</p>
<blockquote>
<div><p>If you want to use another model, you can simply change these three parameters: <code class="docutils literal notranslate"><span class="pre">model_platform</span></code>, <code class="docutils literal notranslate"><span class="pre">model_type</span></code>, <code class="docutils literal notranslate"><span class="pre">model_config_dict</span></code> .</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">camel.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelPlatformType</span><span class="p">,</span> <span class="n">ModelType</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.configs</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatGPTConfig</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAgent</span>

<span class="c1"># Define the model, here in this case we use gpt-4o-mini</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OPENAI</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="n">ModelType</span><span class="o">.</span><span class="n">GPT_4O_MINI</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="n">ChatGPTConfig</span><span class="p">()</span><span class="o">.</span><span class="n">as_dict</span><span class="p">(),</span>
<span class="p">)</span>

<span class="c1"># Define an assistant message</span>
<span class="n">system_msg</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span>

<span class="c1"># Initialize the agent</span>
<span class="n">ChatAgent</span><span class="p">(</span><span class="n">system_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<blockquote>
<div><p>And if you want to use an OpenAI-compatible API, you can replace the <code class="docutils literal notranslate"><span class="pre">model</span></code> with the following code:</p>
</div></blockquote>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OPENAI_COMPATIBLE_MODEL</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;a-string-representing-the-model-type&quot;</span><span class="p">,</span>
    <span class="n">api_key</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_COMPATIBILITY_API_KEY&quot;</span><span class="p">),</span>
    <span class="n">url</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;OPENAI_COMPATIBILITY_API_BASE_URL&quot;</span><span class="p">),</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span> <span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">4096</span><span class="p">},</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-on-device-open-source-models">
<h1>4. Using On-Device Open Source Models<a class="headerlink" href="#using-on-device-open-source-models" title="Link to this heading">#</a></h1>
<p>CAMEL AI also supports local deployment of open-source LLMs. Choose the setup that suits your project:</p>
<section id="using-ollama-to-set-llama-3-locally">
<h2>4.1 Using Ollama to Set Llama 3 Locally<a class="headerlink" href="#using-ollama-to-set-llama-3-locally" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Download <a class="reference external" href="https://ollama.com/download">Ollama</a>.</p></li>
<li><p>After setting up Ollama, pick a model like Llama3 for your project:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>ollama<span class="w"> </span>pull<span class="w"> </span>llama3
</pre></div>
</div>
<ol class="arabic simple" start="3">
<li><p>Create a <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> similar the one below in your project directory. (Optional)</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">FROM</span> <span class="n">llama3</span>

<span class="c1"># Set parameters</span>
<span class="n">PARAMETER</span> <span class="n">temperature</span> <span class="mf">0.8</span>
<span class="n">PARAMETER</span> <span class="n">stop</span> <span class="n">Result</span>

<span class="c1"># Sets a custom system message to specify the behavior of the chat assistant</span>
<span class="c1"># Leaving it blank for now.</span>

<span class="n">SYSTEM</span> <span class="s2">&quot;&quot;&quot; &quot;&quot;&quot;</span>
</pre></div>
</div>
<ol class="arabic simple" start="4">
<li><p>Create a script to get the base model (llama3) and create a custom model using the <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> above. Save this as a <code class="docutils literal notranslate"><span class="pre">.sh</span></code> file: (Optional)</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/zsh

# variables
model_name=&quot;llama3&quot;
custom_model_name=&quot;camel-llama3&quot;

#get the base model
ollama pull $model_name

#create the model file
ollama create $custom_model_name -f ./Llama3ModelFile
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Navigate to the directory where the script and <code class="docutils literal notranslate"><span class="pre">ModelFile</span></code> are located and run the script. Enjoy your Llama3 model, enhanced by CAMEL‚Äôs excellent agents.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">camel.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAgent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelPlatformType</span>

<span class="n">ollama_model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">OLLAMA</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;llama3&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://localhost:11434/v1&quot;</span><span class="p">,</span> <span class="c1"># Optional</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">},</span>
<span class="p">)</span>

<span class="n">agent_sys_msg</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">ChatAgent</span><span class="p">(</span><span class="n">agent_sys_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">ollama_model</span><span class="p">,</span> <span class="n">token_limit</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">user_msg</span> <span class="o">=</span> <span class="s2">&quot;Say hi to CAMEL&quot;</span>

<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">user_msg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assistant_response</span><span class="o">.</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-vllm-to-set-phi-3-locally">
<h2>4.2 Using vLLM to Set Phi-3 Locally<a class="headerlink" href="#using-vllm-to-set-phi-3-locally" title="Link to this heading">#</a></h2>
<p>Install <a class="reference external" href="https://docs.vllm.ai/en/latest/getting_started/installation.html">vLLM</a> first.</p>
<p>After setting up vLLM, start an OpenAI compatible server for example by:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">vllm</span><span class="o">.</span><span class="n">entrypoints</span><span class="o">.</span><span class="n">openai</span><span class="o">.</span><span class="n">api_server</span> <span class="o">--</span><span class="n">model</span> <span class="n">microsoft</span><span class="o">/</span><span class="n">Phi</span><span class="o">-</span><span class="mi">3</span><span class="o">-</span><span class="n">mini</span><span class="o">-</span><span class="mi">4</span><span class="n">k</span><span class="o">-</span><span class="n">instruct</span> <span class="o">--</span><span class="n">api</span><span class="o">-</span><span class="n">key</span> <span class="n">vllm</span> <span class="o">--</span><span class="n">dtype</span> <span class="n">bfloat16</span>
</pre></div>
</div>
<p>Create and run following script (more details please refer to this <a class="reference external" href="https://github.com/camel-ai/camel/blob/master/examples/models/vllm_model_example.py">example</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">camel.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAgent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelPlatformType</span>

<span class="n">vllm_model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">VLLM</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;microsoft/Phi-3-mini-4k-instruct&quot;</span><span class="p">,</span>
    <span class="n">url</span><span class="o">=</span><span class="s2">&quot;http://localhost:8000/v1&quot;</span><span class="p">,</span> <span class="c1"># Optional</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span> <span class="c1"># Optional</span>
<span class="p">)</span>

<span class="n">agent_sys_msg</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">ChatAgent</span><span class="p">(</span><span class="n">agent_sys_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">vllm_model</span><span class="p">,</span> <span class="n">token_limit</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">user_msg</span> <span class="o">=</span> <span class="s2">&quot;Say hi to CAMEL AI&quot;</span>

<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">user_msg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assistant_response</span><span class="o">.</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="using-sglang-to-set-meta-llama-llama-locally">
<h2>4.3 Using SGLang to Set meta-llama/Llama Locally<a class="headerlink" href="#using-sglang-to-set-meta-llama-llama-locally" title="Link to this heading">#</a></h2>
<p>Install <a class="reference external" href="https://sgl-project.github.io/start/install.html">SGLang</a> first.</p>
<p>Create and run following script (more details please refer to this <a class="reference external" href="https://github.com/camel-ai/camel/blob/master/examples/models/sglang_model_example.py">example</a>):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">camel.agents</span><span class="w"> </span><span class="kn">import</span> <span class="n">ChatAgent</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.messages</span><span class="w"> </span><span class="kn">import</span> <span class="n">BaseMessage</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelFactory</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">camel.types</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelPlatformType</span>

<span class="n">sglang_model</span> <span class="o">=</span> <span class="n">ModelFactory</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">model_platform</span><span class="o">=</span><span class="n">ModelPlatformType</span><span class="o">.</span><span class="n">SGLANG</span><span class="p">,</span>
    <span class="n">model_type</span><span class="o">=</span><span class="s2">&quot;meta-llama/Llama-3.2-1B-Instruct&quot;</span><span class="p">,</span>
    <span class="n">model_config_dict</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
    <span class="n">api_key</span><span class="o">=</span><span class="s2">&quot;sglang&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">agent_sys_msg</span> <span class="o">=</span> <span class="s2">&quot;You are a helpful assistant.&quot;</span>

<span class="n">agent</span> <span class="o">=</span> <span class="n">ChatAgent</span><span class="p">(</span><span class="n">agent_sys_msg</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">sglang_model</span><span class="p">,</span> <span class="n">token_limit</span><span class="o">=</span><span class="mi">4096</span><span class="p">)</span>

<span class="n">user_msg</span> <span class="o">=</span> <span class="s2">&quot;Say hi to CAMEL AI&quot;</span>

<span class="n">assistant_response</span> <span class="o">=</span> <span class="n">agent</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">user_msg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">assistant_response</span><span class="o">.</span><span class="n">msg</span><span class="o">.</span><span class="n">content</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
<section id="model-speed-and-performance">
<h1>5 Model Speed and Performance<a class="headerlink" href="#model-speed-and-performance" title="Link to this heading">#</a></h1>
<p>Performance is critical for interactive AI applications. CAMEL-AI benchmarks tokens processed per second across various models:</p>
<p>In <a class="reference internal" href="#../cookbooks/model_speed_comparison.ipynb"><span class="xref myst">this notebook</span></a>, we compared several models, including OpenAI‚Äôs GPT-4O Mini, GPT-4O, O1 Preview, and SambaNova‚Äôs Llama series, by measuring the number of tokens each model processes per second.</p>
<p><strong>Key Insights:</strong> Smaller models like SambaNova‚Äôs Llama 8B and OpenAI‚Äôs GPT-4O Mini typically offer faster responses. Larger models like SambaNova‚Äôs Llama 405B, while more powerful, tend to generate output more slowly due to their complexity. OpenAI models demonstrate relatively consistent performance, while SambaNova‚Äôs Llama 8B significantly outperforms others in speed. The chart below illustrates the tokens per second achieved by each model during our tests:</p>
<p><img alt="Model Speed Comparison: Chart comparing tokens per second for various AI models" src="https://i.postimg.cc/4xByytyZ/model-speed.png" /></p>
<p>For local inference, we conducted a straightforward comparison locally between vLLM and SGLang. SGLang demonstrated superior performance, with <code class="docutils literal notranslate"><span class="pre">meta-llama/Llama-3.2-1B-Instruct</span></code> reaching a peak speed of 220.98 tokens per second, compared to vLLM, which capped at 107.2 tokens per second.</p>
</section>
<section id="next-steps">
<h1>6. Next Steps<a class="headerlink" href="#next-steps" title="Link to this heading">#</a></h1>
<p>You‚Äôve now learned how to integrate various models into CAMEL AI.</p>
<p>Next, check out our guide covering basics of creating and converting <a class="reference external" href="https://docs.camel-ai.org/key_modules/messages.html">messages with BaseMessage.</a></p>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="datagen.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Chain of Thought (CoT) Data Generation</p>
      </div>
    </a>
    <a class="right-next"
       href="messages.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">1. Concept</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">1. Concept</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#supported-model-platforms-in-camel">2. Supported Model Platforms in CAMEL</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-use-models-via-api-calls">3. How to Use Models via API Calls</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#using-on-device-open-source-models">4. Using On-Device Open Source Models</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-ollama-to-set-llama-3-locally">4.1 Using Ollama to Set Llama 3 Locally</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-vllm-to-set-phi-3-locally">4.2 Using vLLM to Set Phi-3 Locally</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#using-sglang-to-set-meta-llama-llama-locally">4.3 Using SGLang to Set meta-llama/Llama Locally</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#model-speed-and-performance">5 Model Speed and Performance</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#next-steps">6. Next Steps</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By CAMEL-AI.org
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      ¬© Copyright 2024, CAMEL-AI.org.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>