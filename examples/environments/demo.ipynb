{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Step Environment in Camel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Step environments are the most widespread type of environment when doing RL with an LLM as policy.\n",
    "\n",
    "It's called *single step* environment, because the agent only does one step. It gets a question sampled from the dataset (the initial state / observation) and then answers. The answer is then scored according to the reward function. Recently, rules-based reward functions, i.e. functions without any learnable parameters, have been successfully used to do RL with LLMs as as policy.\n",
    "\n",
    "First, we have to load a dataset from which we will sample questions. The dataset can be either a `StaticDataset`, which is finite and the length is known at runtime, or it can be a `BaseGenerator`, which is an infinite supply of question - answer pairs, synthetically generated in some way (depending on the implementation).\n",
    "\n",
    "For the sake of simplicity, we will start by loading the MATH dataset, remove unnecessary columns and rename the remaining ones, such that we can easily turn it into a `StaticDataset`, which `SingleStepEnv` can deal with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.cache/pypoetry/virtualenvs/camel-ai-80B0TVyJ-py3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['question', 'final_answer']\n",
      "Example datapoint: question='Let \\\\[f(x) = \\\\left\\\\{\\n\\\\begin{array}{cl} ax+3, &\\\\text{ if }x>2, \\\\\\\\\\nx-5 &\\\\text{ if } -2 \\\\le x \\\\le 2, \\\\\\\\\\n2x-b &\\\\text{ if } x <-2.\\n\\\\end{array}\\n\\\\right.\\\\]Find $a+b$ if the piecewise function is continuous (which means that its graph can be drawn without lifting your pencil from the paper).' final_answer='For the piecewise function to be continuous, the cases must \"meet\" at $2$ and $-2$. For example, $ax+3$ and $x-5$ must be equal when $x=2$. This implies $a(2)+3=2-5$, which we solve to get $2a=-6 \\\\Rightarrow a=-3$. Similarly, $x-5$ and $2x-b$ must be equal when $x=-2$. Substituting, we get $-2-5=2(-2)-b$, which implies $b=3$. So $a+b=-3+3=\\\\boxed{0}$.' rationale=None metadata=None\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from camel.datasets import StaticDataset\n",
    "from camel.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"EleutherAI/hendrycks_math\", \"algebra\")\n",
    "\n",
    "# Preprocess\n",
    "dataset[\"train\"] = dataset[\"train\"].rename_column(\"problem\", \"question\")\n",
    "dataset[\"train\"] = dataset[\"train\"].rename_column(\"solution\", \"final_answer\")\n",
    "dataset[\"train\"] = dataset[\"train\"].remove_columns([\"type\", \"level\"])\n",
    "\n",
    "# This should now print \"['question', 'final_answer']\"\n",
    "print(dataset[\"train\"].column_names)\n",
    "seed_dataset = StaticDataset(dataset['train'])\n",
    "\n",
    "print(\"Example datapoint:\", seed_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will have to define an *extractor*. An extractor takes the LLM response and extracts the verifiable part out of it. Extractors can be initialized with different strategies which modifies the extraction behavior.\n",
    "\n",
    "In the case of the MATH dataset, the final answer is wrapped inside a `\\boxed{...}`, hence we should use the pre-built `BoxedStrategy`.\n",
    "\n",
    "Sadly, MATH answers are rather complicated and a more general Math verifier to compare, for example, equations has not yet been implemented. Hence, we shall prune the dataset to only contain those rows where the content of `\\boxed{...}` is an int. That way, we can do simple verification using the vanilla PythonVerifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints with integer answers: 1228\n"
     ]
    }
   ],
   "source": [
    "from camel.extractors import BaseExtractor, BoxedStrategy\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = BaseExtractor([[BoxedStrategy()]])\n",
    "await extractor.setup()\n",
    "\n",
    "valid_datapoints = []\n",
    "\n",
    "# Iterate through dataset, checking for datapoints with integer answers\n",
    "for datapoint in seed_dataset:\n",
    "    extracted_value = await extractor.extract(response=datapoint.final_answer)\n",
    "\n",
    "    if not extracted_value:\n",
    "        continue\n",
    "    if extracted_value.isdigit() or (\n",
    "        extracted_value.startswith('-') and extracted_value[1:].isdigit()\n",
    "    ):\n",
    "        valid_datapoints.append(\n",
    "            {\n",
    "                \"question\": datapoint.question,\n",
    "                \"final_answer\": datapoint.final_answer,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# We should now have `1228` valid data points.\n",
    "print(f\"Number of datapoints with integer answers: {len(valid_datapoints)}\")\n",
    "\n",
    "filtered_dataset = StaticDataset(valid_datapoints, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Python verifier to later compare answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.verifiers import PythonVerifier\n",
    "\n",
    "verifier = PythonVerifier()\n",
    "await verifier.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now initalize the single step environment with our filtered dataset, our verifier and our extractor.\n",
    "\n",
    "We can then call `env.reset()` to draw from the initial state distribution and return an observation, which can then be fed into the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.environments import Action, SingleStepEnv\n",
    "\n",
    "env = SingleStepEnv(filtered_dataset, verifier, extractor)\n",
    "\n",
    "obs = await env.reset()\n",
    "\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent would then process this observation and select an action, which it would feed into the `step` function. An action in this case would simply be the answer to the question, wrapped in `\\boxed{}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await env.step(Action(llm_response=\"\\\\boxed{5}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the output of the `step` function contains the next observation (which in this case is just a placeholder, since the episode is over), a reward, as well as a reward dict, showing exactly which rubric brought which reward, a `done` flag, indicating that the episode is over and some additional info."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "camel-ai-80B0TVyJ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
