<a id="camel.datagen.self_improving_cot"></a>

# camel.datagen.self\_improving\_cot

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline"></a>

## SelfImprovingCoTPipeline Objects

```python
class SelfImprovingCoTPipeline()
```

Pipeline for generating self-taught reasoning traces
using the self-improving methodology.

This implements the STaR paper's approach of:
1. Initial reasoning trace generation
2. Self-evaluation
3. Feedback-based improvement
4. Iterative refinement

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.__init__"></a>

#### \_\_init\_\_

```python
def __init__(reason_agent: ChatAgent,
             problems: List[Dict],
             max_iterations: int = 3,
             score_threshold: Union[float, Dict[str, float]] = 0.7,
             rejection_sampling_n: Optional[int] = None,
             evaluate_agent: Optional[ChatAgent] = None,
             reward_model: Optional[BaseRewardModel] = None,
             output_path: Optional[str] = None,
             few_shot_examples: Optional[str] = None,
             batch_size: Optional[int] = None,
             max_workers: Optional[int] = None,
             solution_pattern: str = r'\\boxed{(.*?)}',
             trace_pattern: Optional[str] = None)
```

Initialize the self-improving cot pipeline.

**Arguments**:

- `reason_agent` _ChatAgent_ - The chat agent used for generating and
  improving reasoning traces.
- `problems` _List[Dict]_ - List of problem dictionaries to process.
- `max_iterations` _int, optional_ - Maximum number of improvement
  iterations. If set to `0`, the pipeline will generate an
  initial trace without any improvement iterations.
- `(default` - :obj:`3`)
  score_threshold (Union[float, Dict[str, float]], optional):
  Quality threshold. Can be either a single float value applied
  to average score, or a dictionary mapping score dimensions to
  their thresholds. For example: {"correctness": 0.8,
- `"coherence"` - 0.7}. If using reward model and threshold for a
  dimension is not specified, will use the default value 0.7.
- `(default` - :obj:`0.7`)
- `rejection_sampling_n` _int, optional_ - Specifies the number of
  samples to be drawn using the rejection sampling
  method, where samples are accepted or rejected based on
  a predefined condition to achieve a desired distribution.
- `(default` - :obj: `None`)
- `evaluate_agent` _Optional[ChatAgent]_ - The chat agent used for
  evaluating reasoning traces. (default: :obj:`None`)
- `reward_model` _BaseRewardModel, optional_ - Model used to evaluate
  reasoning traces. If `None`, uses Agent self-evaluation.
- `(default` - :obj:`None`)
- `output_path` _str, optional_ - Output path for saving traces. If
  `None`, results will only be returned without saving to file.
- `(default` - :obj:`None`)
- `few_shot_examples` _str, optional_ - Examples to use for few-shot
  generation. (default: :obj:`None`)
- `batch_size` _int, optional_ - Batch size for parallel processing.
- `(default` - :obj:`None`)
- `max_workers` _int, optional_ - Maximum number of worker threads.
- `(default` - :obj:`None`)
- `solution_pattern` _str, optional_ - Regular expression pattern with
  one capture group to extract answers from solution text.
- `(default` - :obj:`r'\\boxed{(.*?)}'`)
- `trace_pattern` _str, optional_ - Regular expression pattern with one
  capture group to extract answers from trace text. If `None`,
  uses the same pattern as solution_pattern.
- `(default` - :obj:`None`)

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.generate_reasoning_trace"></a>

#### generate\_reasoning\_trace

```python
@retry_on_error()
def generate_reasoning_trace(problem: str) -> str
```

Generate initial reasoning trace for a given problem.

**Arguments**:

- `problem` _str_ - The problem text to generate reasoning for.
  

**Returns**:

- `str` - Generated reasoning trace.

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.evaluate_trace"></a>

#### evaluate\_trace

```python
@retry_on_error()
def evaluate_trace(problem: str,
                   trace: str,
                   solution: Optional[str] = None) -> Dict[str, Any]
```

Evaluate the quality of a reasoning trace.

**Arguments**:

- `problem` _str_ - The original problem text to evaluate against.
- `trace` _str_ - The reasoning trace to evaluate.
- `solution` _Optional[str]_ - The solution to the problem, if provided.
- `(default` - :obj:`None`)
  

**Returns**:

  Dict[str, Any]: Evaluation results containing:
  - scores: Dict of evaluation dimensions and their scores
  - feedback: Detailed feedback for improvement
  
  For Agent self-evaluation, the scores will include:
  - correctness: Score for logical correctness
  - clarity: Score for clarity of explanation
  - completeness: Score for completeness of reasoning
  
  For reward model evaluation, the scores will depend on
  the model's evaluation dimensions.

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.generate_reasoning_trace_rejection"></a>

#### generate\_reasoning\_trace\_rejection

```python
@retry_on_error()
def generate_reasoning_trace_rejection(problem: str) -> str
```

Generate multiple candidate reasoning traces for a problem and
select the best one based on evaluation.

**Arguments**:

- `problem` _str_ - The problem text for generating a reasoning trace.
  

**Returns**:

- `str` - The best candidate trace that meets quality criteria, or the
  first candidate if none qualify.

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.improve_trace"></a>

#### improve\_trace

```python
@retry_on_error()
def improve_trace(problem: str,
                  trace: str,
                  feedback: str,
                  solution: Optional[str] = None) -> str
```

Generate improved reasoning trace based on feedback.

**Arguments**:

- `problem` _str_ - The original problem text.
- `trace` _str_ - The current reasoning trace.
- `feedback` _str_ - Feedback for improving the trace.
- `solution` _Optional[str]_ - The solution to the problem, if provided.
- `(default` - :obj:`None`)
  

**Returns**:

- `str` - Improved reasoning trace.

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.validate_problem_format"></a>

#### validate\_problem\_format

```python
def validate_problem_format(problem: Dict) -> None
```

Validate that a problem dictionary has the required format.

**Arguments**:

- `problem` _Dict_ - Problem dictionary to validate.
  

**Raises**:

- `ValueError` - If the problem format is invalid.

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.process_problem"></a>

#### process\_problem

```python
def process_problem(problem: Dict,
                    rationalization: bool = False) -> ProblemResult
```

Process a single problem through the self-improving cot pipeline.

**Arguments**:

- `problem` _Dict_ - Problem dictionary containing the problem text.
- `rationalization` _bool, optional_ - Whether to use rationalization.
- `(default` - :obj:`False`)
  

**Returns**:

- `ProblemResult` - Results with final trace and history.
  

**Raises**:

- `ValueError` - If the problem format is invalid.

<a id="camel.datagen.self_improving_cot.SelfImprovingCoTPipeline.generate"></a>

#### generate

```python
def generate(rationalization: bool = False) -> List[Dict[str, Any]]
```

Execute the self-improving cot pipeline on all problems.

Process problems and return results. If output_path is specified,
also save results to file.

**Arguments**:

- `rationalization` _bool, optional_ - Whether to use rationalization.
- `(default` - :obj:`False`)
  

**Returns**:

  List[Dict[str, Any]]: List of processed results

