---
title: "camel.benchmarks.apibench"
description: "Documentation for the camel.benchmarks.apibench module"
---

<a id="camel.benchmarks.apibench"></a>

# camel.benchmarks.apibench

<a id="camel.benchmarks.apibench.encode_question"></a>

#### encode\_question

```python
def encode_question(question: str, dataset_name: str) -> str
```

Encode multiple prompt instructions into a single string.

<a id="camel.benchmarks.apibench.APIBenchBenchmark"></a>

## APIBenchBenchmark Objects

```python
class APIBenchBenchmark(BaseBenchmark)
```

APIBench Benchmark adopted from `Gorilla: Large Language Model
Connected with Massive APIs`
<https://huggingface.co/datasets/gorilla-llm/APIBench>.

**Arguments**:

- `data_dir` _str_ - The directory to save the data.
- `save_to` _str_ - The file to save the results.
- `processes` _int, optional_ - The number of processes to use.
- `(default` - :obj:`1`)

<a id="camel.benchmarks.apibench.APIBenchBenchmark.__init__"></a>

#### \_\_init\_\_

```python
def __init__(data_dir: str, save_to: str, processes: int = 1)
```

Initialize the APIBench benchmark.

**Arguments**:

- `data_dir` _str_ - The directory to save the data.
- `save_to` _str_ - The file to save the results.
- `processes` _int, optional_ - The number of processes to use for
  parallel processing. (default: :obj:`1`)

<a id="camel.benchmarks.apibench.APIBenchBenchmark.download"></a>

#### download

```python
def download()
```

Download the APIBench dataset.

<a id="camel.benchmarks.apibench.APIBenchBenchmark.load"></a>

#### load

```python
def load(dataset_name: str, force_download: bool = False)
```

Load the APIBench Benchmark dataset.

**Arguments**:

- `dataset_name` _str_ - Name of the specific dataset to be loaded.
- `force_download` _bool, optional_ - Whether to force
  download the data. (default: :obj:`False`)

<a id="camel.benchmarks.apibench.APIBenchBenchmark.run"></a>

#### run

```python
def run(agent: ChatAgent,
        dataset_name: Literal["huggingface", "tensorflowhub", "torchhub"],
        randomize: bool = False,
        subset: Optional[int] = None) -> Dict[str, Any]
```

Run the benchmark.

**Arguments**:

- `agent` _ChatAgent_ - The agent to run the
  benchmark.
  dataset_name (Literal["huggingface",
  "tensorflowhub", "torchhub"]):
  The dataset to run the benchmark.
- `randomize` _bool, optional_ - Whether to randomize the data.
- `(default` - :obj:`False`)
- `subset` _Optional[int], optional_ - The subset of data to run.
- `(default` - :obj:`None`)

