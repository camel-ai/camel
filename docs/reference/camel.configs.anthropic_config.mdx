---
title: "camel.configs.anthropic_config"
description: "Documentation for the camel.configs.anthropic_config module"
---

<a id="camel.configs.anthropic_config"></a>

# camel.configs.anthropic\_config

<a id="camel.configs.anthropic_config.AnthropicConfig"></a>

## AnthropicConfig Objects

```python
class AnthropicConfig(BaseConfig)
```

Defines the parameters for generating chat completions using the
Anthropic API.

See: https://docs.anthropic.com/en/api/messages

**Arguments**:

- `max_tokens` _int, optional_ - The maximum number of tokens to
  generate before stopping. Note that Anthropic models may stop
  before reaching this maximum. This parameter only specifies the
  absolute maximum number of tokens to generate.
- `(default` - :obj:`None`)
- `stop_sequences` _List[str], optional_ - Custom text sequences that will
  cause the model to stop generating. The models will normally stop
  when they have naturally completed their turn. If the model
  encounters one of these custom sequences, the response will be
  terminated and the stop_reason will be "stop_sequence".
- `(default` - :obj:`None`)
- `temperature` _float, optional_ - Amount of randomness injected into the
  response. Defaults to 1. Ranges from 0 to 1. Use temp closer to 0
  for analytical / multiple choice, and closer to 1 for creative
  and generative tasks. Note that even with temperature of 0.0, the
  results will not be fully deterministic. (default: :obj:`None`)
- `top_p` _float, optional_ - Use nucleus sampling. In nucleus sampling, we
  compute the cumulative distribution over all the options for each
  subsequent token in decreasing probability order and cut it off
  once it reaches a particular probability specified by `top_p`.
  You should either alter `temperature` or `top_p`,
  but not both. (default: :obj:`None`)
- `top_k` _int, optional_ - Only sample from the top K options for each
  subsequent token. Used to remove "long tail" low probability
  responses. (default: :obj:`None`)
- `stream` _bool, optional_ - Whether to incrementally stream the response
  using server-sent events. (default: :obj:`None`)
- `metadata` _dict, optional_ - An object describing
  metadata about the request. Can include user_id as an external
  identifier for the user associated with the request.
- `(default` - :obj:`None`)
- `thinking` _dict, optional_ - Configuration for enabling
  Claude's extended thinking. When enabled, responses include
  thinking content blocks showing Claude's thinking process.
- `(default` - :obj:`None`)
- `tool_choice` _dict, optional_ - How the model should
  use the provided tools. The model can use a specific tool, any
  available tool, decide by itself, or not use tools at all.
- `(default` - :obj:`None`)

