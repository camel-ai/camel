<a id="camel.models.ollama_model"></a>

# camel.models.ollama\_model

<a id="camel.models.ollama_model.OllamaModel"></a>

## OllamaModel Objects

```python
class OllamaModel(OpenAICompatibleModel)
```

Ollama service interface.

**Arguments**:

- `model_type` _Union[ModelType, str]_ - Model for which a backend is
  created.
- `model_config_dict` _Optional[Dict[str, Any]], optional_ - A dictionary
  that will be fed into:obj:`openai.ChatCompletion.create()`.
  If:obj:`None`, :obj:`OllamaConfig().as_dict()` will be used.
- `(default` - :obj:`None`)
- `api_key` _Optional[str], optional_ - The API key for authenticating with
  the model service.  Ollama doesn't need API key, it would be
  ignored if set. (default: :obj:`None`)
- `url` _Optional[str], optional_ - The url to the model service.
- `(default` - :obj:`None`)
- `token_counter` _Optional[BaseTokenCounter], optional_ - Token counter to
  use for the model. If not provided, :obj:`OpenAITokenCounter(
  ModelType.GPT_4O_MINI)` will be used.
- `(default` - :obj:`None`)
- `timeout` _Optional[float], optional_ - The timeout value in seconds for
  API calls. If not provided, will fall back to the MODEL_TIMEOUT
  environment variable or default to 180 seconds.
- `(default` - :obj:`None`)
  

**References**:

  https://github.com/ollama/ollama/blob/main/docs/openai.md

<a id="camel.models.ollama_model.OllamaModel.check_model_config"></a>

#### check\_model\_config

```python
def check_model_config()
```

Check whether the model configuration contains any
unexpected arguments to Ollama API.

**Raises**:

- `ValueError` - If the model configuration dictionary contains any
  unexpected arguments to OpenAI API.

