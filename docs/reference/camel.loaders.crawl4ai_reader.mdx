<a id="camel.loaders.crawl4ai_reader"></a>

# camel.loaders.crawl4ai\_reader

<a id="camel.loaders.crawl4ai_reader.Crawl4AI"></a>

## Crawl4AI Objects

```python
class Crawl4AI()
```

Class for converting websites into LLM-ready data.

This class uses asynchronous crawling with CSS selectors or LLM-based
extraction to convert entire websites into structured data.

**References**:

  https://docs.crawl4ai.com/

<a id="camel.loaders.crawl4ai_reader.Crawl4AI.crawl"></a>

#### crawl

```python
async def crawl(start_url: str,
                max_depth: int = 1,
                extraction_strategy=None,
                **kwargs) -> List[Dict[str, Any]]
```

Crawl a URL and its subpages using breadth-first search.

**Arguments**:

- `start_url` _str_ - URL to start crawling from.
- `max_depth` _int, optional_ - Maximum depth of links to follow
- `(default` - :obj:`1`)
- `extraction_strategy` _ExtractionStrategy, optional_ - Strategy
  for data extraction. (default: :obj:`None`)
- `**kwargs` - Additional arguments for crawler configuration.
  

**Returns**:

  List[Dict[str, Any]]: List of crawled page results.
  

**Raises**:

- `RuntimeError` - If an error occurs during crawling.

<a id="camel.loaders.crawl4ai_reader.Crawl4AI.scrape"></a>

#### scrape

```python
async def scrape(url: str,
                 extraction_strategy=None,
                 **kwargs) -> Dict[str, Any]
```

Scrape a single URL using CSS or LLM-based extraction.

**Arguments**:

- `url` _str_ - URL to scrape.
- `extraction_strategy` _ExtractionStrategy, optional_ - Extraction
  strategy to use. (default: :obj:`None`)
- `**kwargs` - Additional arguments for crawler configuration.
  

**Returns**:

  Dict[str, Any]: Dictionary containing scraped data such as markdown
  and HTML content.
  

**Raises**:

- `RuntimeError` - If scraping fails.

<a id="camel.loaders.crawl4ai_reader.Crawl4AI.structured_scrape"></a>

#### structured\_scrape

```python
async def structured_scrape(url: str,
                            response_format: BaseModel,
                            api_key: Optional[str] = None,
                            llm_provider: str = 'ollama/llama3',
                            **kwargs) -> Any
```

Extract structured data from a URL using an LLM.

**Arguments**:

- `url` _str_ - URL to scrape.
- `response_format` _BaseModel_ - Model defining the expected output
  schema.
- `api_key` _str, optional_ - API key for the LLM provider
- `(default` - :obj:`None`).
- `llm_provider` _str, optional_ - Identifier for the LLM provider
- `(default` - :obj:`'ollama/llama3'`).
- `**kwargs` - Additional arguments for crawler configuration.
  

**Returns**:

- `Any` - Crawl result containing the extracted data
  structured according to the schema.
  

**Raises**:

- `ValidationError` - If extracted data does not match the schema.
- `RuntimeError` - If extraction fails.

<a id="camel.loaders.crawl4ai_reader.Crawl4AI.map_site"></a>

#### map\_site

```python
async def map_site(start_url: str, **kwargs) -> List[str]
```

Map a website by extracting all accessible URLs.

**Arguments**:

- `start_url` _str_ - Starting URL to map.
- `**kwargs` - Additional configuration arguments.
  

**Returns**:

- `List[str]` - List of URLs discovered on the website.
  

**Raises**:

- `RuntimeError` - If mapping fails.

