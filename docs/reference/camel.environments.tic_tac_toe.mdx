<a id="camel.environments.tic_tac_toe"></a>

# camel.environments.tic\_tac\_toe

<a id="camel.environments.tic_tac_toe.MoveExtractor"></a>

## MoveExtractor Objects

```python
class MoveExtractor(BaseExtractorStrategy)
```

A strategy for extracting Tic Tac Toe actions from text.

<a id="camel.environments.tic_tac_toe.MoveExtractor.extract"></a>

#### extract

```python
async def extract(text: str) -> Optional[str]
```

Extract a valid Tic Tac Toe move from text.

Looks for a pattern '<Action> n' where n is a digit between 1 and 9.

**Arguments**:

- `text` _str_ - The text to extract the action from.
  

**Returns**:

- `Optional[str]` - The extracted move as a string, or None if no valid
  move is found.

<a id="camel.environments.tic_tac_toe.Opponent"></a>

## Opponent Objects

```python
class Opponent()
```

AI opponent for the Tic Tac Toe game.

This class implements different playing strategies for the AI opponent,
including an optimal strategy using the minimax algorithm with alpha-beta
pruning, and a random strategy.

<a id="camel.environments.tic_tac_toe.Opponent.__init__"></a>

#### \_\_init\_\_

```python
def __init__(play_style: Literal["optimal", "random"] = "optimal") -> None
```

Initialize the opponent with a specific play style.

**Arguments**:

- `play_style` _Literal["optimal", "random"]_ - The strategy to use,
  either "optimal" or "random". (default: :obj:`"optimal"`)

<a id="camel.environments.tic_tac_toe.Opponent.select_move"></a>

#### select\_move

```python
def select_move(board: List[str]) -> Optional[int]
```

Select a move based on the opponent's play style.

**Arguments**:

- `board` _List[str]_ - The current game board as a list of strings.
  

**Returns**:

- `Optional[int]` - The index of the selected move, or None if no move
  is available.

<a id="camel.environments.tic_tac_toe.Opponent.get_optimal_move"></a>

#### get\_optimal\_move

```python
def get_optimal_move(board: List[str]) -> Optional[int]
```

Get the optimal move using the minimax algorithm.

**Arguments**:

- `board` _List[str]_ - The current game board as a list of strings.
  

**Returns**:

- `Optional[int]` - The index of the optimal move, or None if no move
  is available.

<a id="camel.environments.tic_tac_toe.Opponent.minimax"></a>

#### minimax

```python
def minimax(board: List[str],
            is_maximizing: bool,
            depth: int = 0,
            alpha: float = -math.inf,
            beta: float = math.inf) -> Tuple[float, Optional[int]]
```

Minimax algorithm with alpha-beta pruning for optimal move
selection.

Recursively evaluates all possible moves to find the best one.
Uses alpha-beta pruning to reduce the search space.

**Arguments**:

- `board` _List[str]_ - The current game board as a list of strings.
- `is_maximizing` _bool_ - True if maximizing player (O), False if
  minimizing (X).
- `depth` _int_ - Current depth in the search tree. (default: :obj:`0`)
- `alpha` _float_ - Alpha value for pruning. (default: :obj:`-math.inf`)
- `beta` _float_ - Beta value for pruning. (default: :obj:`math.inf`)
  

**Returns**:

  Tuple[float, Optional[int]]: A tuple containing:
  - float: The score of the best move (1 for O win, -1 for X
  win, 0 for draw)
  - Optional[int]: The index of the best move, or None if
  terminal state

<a id="camel.environments.tic_tac_toe.TicTacToeEnv"></a>

## TicTacToeEnv Objects

```python
class TicTacToeEnv(MultiStepEnv)
```

A Tic Tac Toe environment for reinforcement learning with LLMs.

This environment implements a standard Tic Tac Toe game where the LLM agent
plays as 'X' against an AI opponent that plays as 'O'. The opponent can use
either an optimal strategy (minimax with alpha-beta pruning) or a random
strategy.

<a id="camel.environments.tic_tac_toe.TicTacToeEnv.__init__"></a>

#### \_\_init\_\_

```python
def __init__(extractor: Optional[BaseExtractor] = None,
             max_steps: Optional[int] = None,
             play_style: Literal["optimal", "random"] = "optimal",
             **kwargs) -> None
```

Initialize the Tic Tac Toe environment.

**Arguments**:

- `extractor` _Optional[BaseExtractor]_ - Extractor to process LLM
  responses. If None, a default extractor with
  MoveExtractor will be used. (default: :obj:`None`)
- `max_steps` _Optional[int]_ - Maximum steps per episode.
- `(default` - :obj:`None`)
- `play_style` _Literal["optimal", "random"]_ - The strategy for the
  opponent to use, either "optimal" or "random". (default:
  :obj:`"optimal"`)
- `**kwargs` - Additional environment parameters.

<a id="camel.environments.tic_tac_toe.TicTacToeEnv.compute_reward"></a>

#### compute\_reward

```python
async def compute_reward() -> Tuple[float, Dict[str, float]]
```

Compute the reward for the current state.

**Returns**:

  Tuple[float, Dict[str, float]]: A tuple containing the total
  reward and a dictionary of reward components:
  - 1.0 for a win
  - 0.0 for a loss or illegal move
  - 0.5 for a draw
  - For ongoing games, returns an evaluation of the position

<a id="camel.environments.tic_tac_toe.TicTacToeEnv.evaluate_position_for_x"></a>

#### evaluate\_position\_for\_x

```python
@staticmethod
def evaluate_position_for_x(board: List[str],
                            is_x_turn: bool,
                            depth: int = 0,
                            max_depth: int = 10) -> float
```

Evaluate the current board position from X's perspective.

Uses minimax to determine the value of the position.

**Arguments**:

- `board` _List[str]_ - The current game board as a list of strings.
- `is_x_turn` _bool_ - True if it's X's turn to move, False otherwise.
  

**Returns**:

- `float` - A float value representing the position evaluation:
  - 1.0 if X has a winning position
  - 0.0 if O has a winning position
  - 0.5 for a draw
  - For ongoing positions, returns the expected outcome with
  perfect play

<a id="camel.environments.tic_tac_toe.TicTacToeEnv.available_moves"></a>

#### available\_moves

```python
@staticmethod
def available_moves(board: List[str]) -> List[int]
```

Get all available moves on the board.

**Arguments**:

- `board` _List[str]_ - The current game board as a list of strings.
  

**Returns**:

- `List[int]` - A list of indices representing empty cells on the board.

<a id="camel.environments.tic_tac_toe.TicTacToeEnv.check_winner"></a>

#### check\_winner

```python
@staticmethod
def check_winner(board: List[str]) -> Optional[Literal["X", "O", "draw"]]
```

Check if there is a winner or a draw on the board.

**Arguments**:

- `board` _List[str]_ - The current game board as a list of strings.
  

**Returns**:

  Optional[Literal["X", "O", "draw"]]: "X" if X has won, "O" if O
  has won, "draw" if the game is a draw, or None if the game is
  still ongoing.

<a id="camel.environments.tic_tac_toe.TicTacToeEnv.render_board"></a>

#### render\_board

```python
def render_board(board: List[str]) -> str
```

Render the board as a string for display.

**Arguments**:

- `board` _List[str]_ - The current game board as a list of strings.
  

**Returns**:

- `str` - A formatted string representation of the board.

