{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single Step environments are the most widespread type of environment when doing RL with an LLM as policy.\n",
    "\n",
    "It's called *single step* environment, because the agent only does one step. It gets a question sampled from the dataset (the initial state / observation) and then answers. The answer is then scored according to the reward function. Recently, rules-based reward functions, i.e. functions without any learnable parameters, have been successfully used to do RL with LLMs as as policy.\n",
    "\n",
    "Since many RL algorithms (such as GRPO) need multiple rollouts at each step, batching is important to guarantee concurrency / parallelism. This notebook will show how to use batched environments.\n",
    "\n",
    "First, we have to load a dataset from which we will sample questions. The dataset can be either a `StaticDataset`, which is finite and the length is known at runtime, or it can be a `BaseGenerator`, which is an infinite supply of question - answer pairs, synthetically generated in some way (depending on the implementation).\n",
    "\n",
    "We already have a simple script where we use a `StaticDataset`. In here, we will use the `FewShotGenerator` which will generate us new DataPoints on the fly.\n",
    "\n",
    "First, we need a Seed Dataset for the `FewShotGenerator` to sample from. For this, let's create a `StaticDataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.datasets import StaticDataset\n",
    "from camel.logger import get_logger\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "raw_data = [\n",
    "    {\n",
    "        \"question\": \"Evaluate the limit as x approaches 0 of (sin(3*x) - 3*x) / x**3.\",  # noqa: E501\n",
    "        \"final_answer\": \"-9/2\",\n",
    "        \"rationale\": '''from sympy import symbols, limit, sin\n",
    "x = symbols('x')\n",
    "expr = (sin(3*x) - 3*x) / x**3\n",
    "result = limit(expr, x, 0)\n",
    "print(result)''',\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Evaluate the definite integral of (1 - x**2)**3 from x = 0 to x = 1.\",  # noqa: E501\n",
    "        \"final_answer\": \"16/35\",\n",
    "        \"rationale\": '''from sympy import symbols, integrate\n",
    "x = symbols('x')\n",
    "expr = (1 - x**2)**3\n",
    "result = integrate(expr, (x, 0, 1))\n",
    "print(result)''',\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Evaluate the limit as n approaches infinity of n*(sqrt(n**2 + 1) - n).\",  # noqa: E501\n",
    "        \"final_answer\": \"1/2\",\n",
    "        \"rationale\": '''from sympy import symbols, limit, sqrt\n",
    "n = symbols('n', positive=True)\n",
    "expr = n*(sqrt(n**2 + 1) - n)\n",
    "result = limit(expr, n, float(\"inf\"))\n",
    "print(result)''',\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Compute the sum of the series sum from n = 1 to 50 of 1/(n*(n+1)).\",  # noqa: E501\n",
    "        \"final_answer\": \"50/51\",\n",
    "        \"rationale\": '''from sympy import symbols, summation\n",
    "n = symbols('n', positive=True, integer=True)\n",
    "expr = 1/(n*(n+1))\n",
    "result = summation(expr, (n, 1, 50))\n",
    "print(result)''',\n",
    "    },\n",
    "]\n",
    "\n",
    "seed_dataset = StaticDataset(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FewShotGenerator` needs an python interpreter to compute a pseudo ground truth from the code it generated. For this, let's define a `PythonVerifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.verifiers import PythonVerifier\n",
    "\n",
    "verifier = PythonVerifier(required_packages=[\"sympy\"])\n",
    "await verifier.setup(uv=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we need a Model to generate the synthetic datapoints. Let's use the `ModelFactory`.\n",
    "\n",
    "Note: We use GPT-4o Mini as a default here, feel free to use other models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "openai_api_key = getpass('Enter your OpenAI API key: ')\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from camel.configs import ChatGPTConfig\n",
    "from camel.datasets import FewShotGenerator\n",
    "\n",
    "model = ModelFactory.create(\n",
    "    model_platform=ModelPlatformType.OPENAI,\n",
    "    model_type=ModelType.GPT_4O_MINI,\n",
    "    model_config_dict=ChatGPTConfig().as_dict(),\n",
    ")\n",
    "\n",
    "# Note: When the generator needs to create new datapoints, it will on default create 20 new datapoints\n",
    "# Since we are paying for the API, let's set this number to 2 instead\n",
    "generator = FewShotGenerator(\n",
    "    puffer=2, seed_dataset=seed_dataset, verifier=verifier, model=model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our generator is all set up, let's create a `SingleStepEnv`.\n",
    "\n",
    "We can then call `env.reset()` to draw from the initial state distribution and return an observation, which can then be fed into the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.environments import Action, SingleStepEnv\n",
    "\n",
    "env = SingleStepEnv(generator, verifier)\n",
    "\n",
    "obs = await env.reset(seed=42)\n",
    "\n",
    "print(obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The agent would then process this observation and select an action, which it would feed into the `step` function. For this, we will make use of *extractor*. An extractor takes the LLM response and extracts the verifiable part out of it. Extractors can be initialized with different strategies which modifies the extraction behavior. We then compare it to our computed pseudo ground truth which we got internally by running the code in the rationale with the `PythonVerifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from camel.agents import ChatAgent\n",
    "from camel.extractors import BaseExtractor, BoxedStrategy\n",
    "\n",
    "# Initialize extractor\n",
    "extractor = BaseExtractor([[BoxedStrategy()]])\n",
    "await extractor.setup()\n",
    "agent = ChatAgent(model=model)\n",
    "\n",
    "SYSTEM_PROMPT = r\"\"\"System Prompt:\n",
    "You are a helpful AI designed to answer mathematical questions with clarity and precision. Your task is to provide a step-by-step explanation for \n",
    "any mathematical problem posed by the user, ensuring the response is easy to follow. Adhere to these guidelines:\n",
    "Analyze the mathematical question carefully and break down the solution process into clear, logical steps.\n",
    "Use natural language to explain each step, incorporating LaTeX notation (e.g., $x + 2$) \n",
    "for mathematical expressions when helpful. Conclude your response with the final answer enclosed \n",
    "in a LaTeX \\boxed{} environment (e.g., \\boxed{5}). \n",
    "Place this at the end of your explanation as a standalone statement.\n",
    "\n",
    "The question you should answer is: \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compare the agents output to our pseudo ground truth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.step(SYSTEM_PROMPT + obs.question)\n",
    "\n",
    "proposed_solution = await extractor.extract(response.msgs[0].content)\n",
    "\n",
    "result = await env.step(Action(index=0, llm_response=proposed_solution))\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
