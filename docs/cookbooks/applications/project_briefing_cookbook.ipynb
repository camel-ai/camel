{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be8f1f9e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Project Briefing Generator Cookbook\n",
    "\n",
    "A comprehensive guide for building an AI-powered project briefing system using CAMEL-AI and Mem0 for intelligent knowledge management and context-aware briefing generation.\n",
    "\n",
    "## Overview\n",
    "\n",
    "This cookbook demonstrates how to create a system that can:\n",
    "- Store and organize project knowledge using vector-based memory\n",
    "- Generate role-specific project briefings for new team members\n",
    "- Answer contextual questions about project decisions and history\n",
    "- Manage project memories with semantic search capabilities\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae1248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Core dependencies\n",
    "pip install mem0ai camel-ai python-dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a014c81c",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "Create a `.env` file with your API keys:\n",
    "```env\n",
    "OPENAI_API_KEY=your_openai_api_key_here\n",
    "```\n",
    "\n",
    "## Core Architecture\n",
    "\n",
    "### 1. System Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ddd64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List, Dict\n",
    "from mem0 import Memory\n",
    "from camel.agents import ChatAgent\n",
    "from camel.messages import BaseMessage\n",
    "from camel.models import ModelFactory\n",
    "from camel.types import ModelPlatformType, ModelType\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "class ProjectBriefingSystem:\n",
    "    def __init__(self):\n",
    "        # Load environment variables\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Initialize Mem0 with fallback options\n",
    "        self.memory = self._initialize_memory()\n",
    "        \n",
    "        # Initialize CAMEL agents\n",
    "        self.knowledge_agent = self._create_agent(\n",
    "            \"Knowledge Extractor\", \n",
    "            \"You extract and organize project knowledge from documents and conversations.\"\n",
    "        )\n",
    "        \n",
    "        self.briefing_agent = self._create_agent(\n",
    "            \"Briefing Generator\",\n",
    "            \"You create comprehensive project briefings for new team members.\"\n",
    "        )\n",
    "        \n",
    "        self.qa_agent = self._create_agent(\n",
    "            \"Q&A Assistant\",\n",
    "            \"You answer specific questions about project decisions and context.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b9a1a",
   "metadata": {},
   "source": [
    "### 2. Memory Initialization with Fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67780c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _initialize_memory(self):\n",
    "    \"\"\"Initialize Mem0 with multiple fallback strategies\"\"\"\n",
    "    try:\n",
    "        # Method 1: Simple initialization\n",
    "        return Memory()\n",
    "    except Exception as e1:\n",
    "        print(f\"Default initialization failed: {e1}\")\n",
    "        \n",
    "        try:\n",
    "            # Method 2: With basic configuration\n",
    "            config = {\n",
    "                \"vector_store\": {\n",
    "                    \"provider\": \"chroma\",\n",
    "                    \"config\": {\n",
    "                        \"collection_name\": \"project_briefings\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            return Memory(config)\n",
    "        except Exception as e2:\n",
    "            print(f\"Configured initialization failed: {e2}\")\n",
    "            \n",
    "            # Method 3: Fallback to in-memory storage\n",
    "            print(\"Using fallback in-memory storage...\")\n",
    "            self.memory_store = {}\n",
    "            return None\n",
    "\n",
    "def _create_agent(self, role: str, description: str) -> ChatAgent:\n",
    "    \"\"\"Create a CAMEL agent with specified role and description\"\"\"\n",
    "    model = ModelFactory.create(\n",
    "        model_platform=ModelPlatformType.OPENAI,\n",
    "        model_type=ModelType.GPT_4O_MINI\n",
    "    )\n",
    "    \n",
    "    return ChatAgent(\n",
    "        system_message=BaseMessage.make_assistant_message(\n",
    "            role_name=role,\n",
    "            content=description\n",
    "        ),\n",
    "        model=model\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091177be",
   "metadata": {},
   "source": [
    "## Core Features\n",
    "\n",
    "### 3. Storing Project Knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2e9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_project_info(self, content: str, project_id: str, content_type: str):\n",
    "    \"\"\"Store project information with metadata\"\"\"\n",
    "    metadata = {\n",
    "        \"project_id\": project_id,\n",
    "        \"content_type\": content_type,\n",
    "        \"timestamp\": time.time(),\n",
    "        \"date\": time.strftime(\"%Y-%m-%d\", time.localtime())\n",
    "    }\n",
    "    \n",
    "    if self.memory is not None:\n",
    "        # Use Mem0 vector storage\n",
    "        try:\n",
    "            result = self.memory.add(content, user_id=project_id, metadata=metadata)\n",
    "            print(f\"âœ… Information stored in Mem0: {result}\")\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            # Try alternative format\n",
    "            try:\n",
    "                result = self.memory.add(\n",
    "                    messages=[{\"role\": \"user\", \"content\": content}], \n",
    "                    user_id=project_id, \n",
    "                    metadata=metadata\n",
    "                )\n",
    "                print(f\"âœ… Information stored (messages format): {result}\")\n",
    "                return result\n",
    "            except Exception as e2:\n",
    "                # Simple add without metadata\n",
    "                result = self.memory.add(content, user_id=project_id)\n",
    "                print(f\"âœ… Information stored (simple): {result}\")\n",
    "                return result\n",
    "    else:\n",
    "        # Use fallback storage\n",
    "        key = f\"{project_id}_{content_type}_{int(time.time())}\"\n",
    "        self.memory_store[key] = {\n",
    "            \"content\": content,\n",
    "            \"project_id\": project_id,\n",
    "            \"content_type\": content_type,\n",
    "            \"timestamp\": time.time()\n",
    "        }\n",
    "        print(\"âœ… Information stored in fallback memory\")\n",
    "        return {\"message\": \"Stored in fallback memory\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be14f4eb",
   "metadata": {},
   "source": [
    "### 4. Retrieving Contextual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717c153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_project_context(self, query: str, project_id: str, limit: int = 10) -> List[Dict]:\n",
    "    \"\"\"Retrieve relevant project context using semantic search\"\"\"\n",
    "    if self.memory is not None:\n",
    "        try:\n",
    "            # Use Mem0 semantic search\n",
    "            results = self.memory.search(query=query, user_id=project_id, limit=limit)\n",
    "            if results:\n",
    "                print(f\"ðŸ“Š Found {len(results)} relevant memories\")\n",
    "                return results\n",
    "            else:\n",
    "                print(\"No relevant memories found\")\n",
    "                return []\n",
    "        except Exception as e:\n",
    "            print(f\"Search failed: {e}\")\n",
    "            # Fallback to getting all memories and filtering\n",
    "            try:\n",
    "                all_memories = self.memory.get_all(user_id=project_id)\n",
    "                if all_memories:\n",
    "                    # Simple keyword filtering\n",
    "                    query_words = query.lower().split()\n",
    "                    filtered = []\n",
    "                    for item in all_memories:\n",
    "                        content = str(item.get('memory', '') or item.get('text', '')).lower()\n",
    "                        if any(word in content for word in query_words):\n",
    "                            filtered.append(item)\n",
    "                    print(f\"ðŸ“Š Found {len(filtered)} memories (keyword search)\")\n",
    "                    return filtered[:limit]\n",
    "                return []\n",
    "            except Exception as e2:\n",
    "                print(f\"Fallback search failed: {e2}\")\n",
    "                return []\n",
    "    else:\n",
    "        # Use fallback storage with keyword search\n",
    "        results = []\n",
    "        query_words = query.lower().split()\n",
    "        \n",
    "        for key, data in self.memory_store.items():\n",
    "            if data[\"project_id\"] == project_id:\n",
    "                content_lower = data[\"content\"].lower()\n",
    "                score = sum(content_lower.count(word) for word in query_words if word in content_lower)\n",
    "                \n",
    "                if score > 0:\n",
    "                    results.append({\n",
    "                        \"memory\": data[\"content\"],\n",
    "                        \"score\": score,\n",
    "                        \"metadata\": {\n",
    "                            \"content_type\": data[\"content_type\"],\n",
    "                            \"timestamp\": data.get(\"timestamp\", 0)\n",
    "                        }\n",
    "                    })\n",
    "        \n",
    "        results.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "        print(f\"ðŸ“Š Found {len(results)} relevant memories from fallback\")\n",
    "        return results[:limit]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683829a",
   "metadata": {},
   "source": [
    "### 5. Generating Project Briefings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3aa4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_briefing(self, project_id: str, new_member_role: str) -> str:\n",
    "    \"\"\"Generate comprehensive project briefing for new team members\"\"\"\n",
    "    \n",
    "    # Define search queries for comprehensive context\n",
    "    context_queries = [\n",
    "        f\"project overview {new_member_role}\",\n",
    "        \"key decisions rationale\",\n",
    "        \"timeline milestones\",\n",
    "        \"team structure contacts\",\n",
    "        \"technical architecture\",\n",
    "        \"current status challenges\"\n",
    "    ]\n",
    "    \n",
    "    # Gather context from multiple searches\n",
    "    all_context = []\n",
    "    for query in context_queries:\n",
    "        context = self.retrieve_project_context(query, project_id, limit=5)\n",
    "        all_context.extend(context)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    seen_content = set()\n",
    "    unique_context = []\n",
    "    for item in all_context:\n",
    "        content = item.get('memory', '') or item.get('text', '') or str(item)\n",
    "        if content not in seen_content and content.strip():\n",
    "            seen_content.add(content)\n",
    "            unique_context.append(item)\n",
    "    \n",
    "    # Build context text\n",
    "    context_text = \"\"\n",
    "    if unique_context:\n",
    "        for item in unique_context:\n",
    "            memory_text = item.get('memory', '') or item.get('text', '') or str(item)\n",
    "            metadata = item.get('metadata', {})\n",
    "            content_type = metadata.get('content_type', 'Unknown')\n",
    "            date = metadata.get('date', 'Unknown date')\n",
    "            context_text += f\"[{content_type} - {date}]: {memory_text}\\n\\n\"\n",
    "    else:\n",
    "        context_text = \"No previous project information found. This appears to be a new project.\"\n",
    "    \n",
    "    # Generate briefing prompt\n",
    "    prompt = f\"\"\"\n",
    "    Generate a comprehensive project briefing for a new {new_member_role} joining the team.\n",
    "    \n",
    "    Project Context (from project memory):\n",
    "    {context_text}\n",
    "    \n",
    "    Create a well-structured briefing that includes:\n",
    "    1. **Project Overview** - What is this project about?\n",
    "    2. **Key Decisions & Rationale** - Important decisions made and why\n",
    "    3. **Technical Architecture** - Tech stack and architectural decisions\n",
    "    4. **Team Structure** - Who's working on what\n",
    "    5. **Current Status** - Where we are now\n",
    "    6. **Challenges & Blockers** - Current issues to be aware of\n",
    "    7. **Next Steps** - What the new {new_member_role} should focus on\n",
    "    8. **Important Contacts** - Key people to connect with\n",
    "    9. **Resources & Documentation** - Where to find more information\n",
    "    \n",
    "    Make it specific to a {new_member_role} role and actionable.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = self.briefing_agent.step(BaseMessage.make_user_message(\n",
    "            role_name=\"User\",\n",
    "            content=prompt\n",
    "        ))\n",
    "        return response.msg.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating briefing: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e0019c",
   "metadata": {},
   "source": [
    "### 6. Question Answering System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d301bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question(self, question: str, project_id: str) -> str:\n",
    "    \"\"\"Answer specific questions about the project using contextual memory\"\"\"\n",
    "    \n",
    "    # Search for relevant context\n",
    "    context = self.retrieve_project_context(question, project_id, limit=8)\n",
    "    \n",
    "    # Build context from search results\n",
    "    context_text = \"\"\n",
    "    if context:\n",
    "        for item in context:\n",
    "            memory_text = item.get('memory', '') or item.get('text', '') or str(item)\n",
    "            metadata = item.get('metadata', {})\n",
    "            content_type = metadata.get('content_type', 'Unknown')\n",
    "            date = metadata.get('date', 'Unknown date')\n",
    "            context_text += f\"[{content_type} - {date}]: {memory_text}\\n\\n\"\n",
    "    else:\n",
    "        context_text = \"No relevant project information found for this question.\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Answer this question based on the project context from memory:\n",
    "    \n",
    "    **Question:** {question}\n",
    "    \n",
    "    **Project Context:**\n",
    "    {context_text}\n",
    "    \n",
    "    Provide a detailed, accurate answer based on the available information. \n",
    "    If the context doesn't contain enough information to answer completely, \n",
    "    mention what information is missing and suggest where it might be found.\n",
    "    \n",
    "    Include specific details and reasoning from the project memory when available.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = self.qa_agent.step(BaseMessage.make_user_message(\n",
    "            role_name=\"User\",\n",
    "            content=prompt\n",
    "        ))\n",
    "        return response.msg.content\n",
    "    except Exception as e:\n",
    "        return f\"Error answering question: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9557f06f",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "### Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893a3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the system\n",
    "briefing_system = ProjectBriefingSystem()\n",
    "\n",
    "# Store project knowledge\n",
    "project_id = \"project_alpha\"\n",
    "\n",
    "# Add various types of project information\n",
    "briefing_system.store_project_info(\n",
    "    content=\"Decided to migrate from MongoDB to PostgreSQL for better ACID compliance. Migration scheduled for Q2 2024.\",\n",
    "    project_id=project_id,\n",
    "    content_type=\"Decision Log\"\n",
    ")\n",
    "\n",
    "briefing_system.store_project_info(\n",
    "    content=\"Team structure: 3 backend developers, 2 frontend developers, 1 DevOps engineer, 1 Product Manager\",\n",
    "    project_id=project_id,\n",
    "    content_type=\"Team Update\"\n",
    ")\n",
    "\n",
    "briefing_system.store_project_info(\n",
    "    content=\"Architecture uses microservices with Docker containers, deployed on AWS EKS\",\n",
    "    project_id=project_id,\n",
    "    content_type=\"Technical Doc\"\n",
    ")\n",
    "\n",
    "# Generate a briefing for a new developer\n",
    "briefing = briefing_system.generate_briefing(project_id, \"Backend Developer\")\n",
    "print(\"Generated Briefing:\")\n",
    "print(briefing)\n",
    "\n",
    "# Ask specific questions\n",
    "answer = briefing_system.answer_question(\n",
    "    \"Why did we switch from MongoDB to PostgreSQL?\", \n",
    "    project_id\n",
    ")\n",
    "print(\"\\nQ&A Answer:\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de66e78",
   "metadata": {},
   "source": [
    "### Batch Processing Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58fb81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_store_project_data(briefing_system, project_id: str, data_entries: List[Dict]):\n",
    "    \"\"\"Store multiple project entries at once\"\"\"\n",
    "    results = []\n",
    "    for entry in data_entries:\n",
    "        try:\n",
    "            result = briefing_system.store_project_info(\n",
    "                content=entry['content'],\n",
    "                project_id=project_id,\n",
    "                content_type=entry['type']\n",
    "            )\n",
    "            results.append({\"success\": True, \"result\": result})\n",
    "        except Exception as e:\n",
    "            results.append({\"success\": False, \"error\": str(e)})\n",
    "    return results\n",
    "\n",
    "# Example batch data\n",
    "project_data = [\n",
    "    {\n",
    "        \"content\": \"Sprint 1 completed. Delivered user authentication and basic dashboard.\",\n",
    "        \"type\": \"Sprint Update\"\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"API rate limiting implemented using Redis. Max 1000 requests per hour per user.\",\n",
    "        \"type\": \"Technical Decision\"\n",
    "    },\n",
    "    {\n",
    "        \"content\": \"New team member Sarah joins as Senior Frontend Developer on March 1st.\",\n",
    "        \"type\": \"Team Update\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Store batch data\n",
    "results = batch_store_project_data(briefing_system, \"project_beta\", project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08403d0",
   "metadata": {},
   "source": [
    "### Advanced Memory Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d111b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_project_memories(self, project_id: str) -> List[Dict]:\n",
    "    \"\"\"Retrieve all memories for a specific project\"\"\"\n",
    "    try:\n",
    "        if self.memory is not None:\n",
    "            memories = self.memory.get_all(user_id=project_id)\n",
    "            return memories if memories else []\n",
    "        else:\n",
    "            # Use fallback storage\n",
    "            project_memories = []\n",
    "            for key, data in self.memory_store.items():\n",
    "                if data[\"project_id\"] == project_id:\n",
    "                    project_memories.append({\n",
    "                        \"memory\": data[\"content\"],\n",
    "                        \"metadata\": {\n",
    "                            \"content_type\": data[\"content_type\"],\n",
    "                            \"timestamp\": data.get(\"timestamp\", 0)\n",
    "                        }\n",
    "                    })\n",
    "            return project_memories\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting memories: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def delete_memory(self, memory_id: str, project_id: str) -> bool:\n",
    "    \"\"\"Delete a specific memory\"\"\"\n",
    "    try:\n",
    "        if self.memory is not None:\n",
    "            result = self.memory.delete(memory_id=memory_id, user_id=project_id)\n",
    "            return True\n",
    "        else:\n",
    "            # Delete from fallback storage\n",
    "            keys_to_delete = [\n",
    "                key for key, data in self.memory_store.items()\n",
    "                if data[\"project_id\"] == project_id and str(data.get(\"timestamp\", \"\")) == memory_id\n",
    "            ]\n",
    "            for key in keys_to_delete:\n",
    "                del self.memory_store[key]\n",
    "            return len(keys_to_delete) > 0\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting memory: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7e4ca",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Best Practices\n",
    "\n",
    "### Content Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901414a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good: Structured content with context\n",
    "content = \"\"\"\n",
    "Decision: Switched from REST to GraphQL for API\n",
    "Date: 2024-01-15\n",
    "Reason: Better data fetching efficiency, reduced over-fetching\n",
    "Impact: Frontend team needs to update client libraries\n",
    "Stakeholders: Backend team, Frontend team, Product team\n",
    "Timeline: Implementation by end of Q1 2024\n",
    "\"\"\"\n",
    "\n",
    "# Better: Include reasoning and next steps\n",
    "content = \"\"\"\n",
    "Technical Decision - API Architecture Change\n",
    "\n",
    "What: Migrated from REST API to GraphQL\n",
    "When: January 15, 2024\n",
    "Why: \n",
    "- Reduced over-fetching by 40%\n",
    "- Better developer experience for frontend team\n",
    "- Improved mobile app performance\n",
    "\n",
    "Impact:\n",
    "- All frontend clients need updates\n",
    "- New GraphQL playground for testing\n",
    "- Updated documentation required\n",
    "\n",
    "Next Steps:\n",
    "- Frontend team training scheduled for Jan 22\n",
    "- Client library migration by Feb 1\n",
    "- Legacy REST endpoints deprecated by March 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3191471d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Effective Questioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5213c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of effective questions for the Q&A system\n",
    "effective_questions = [\n",
    "    \"Why did we choose technology X over Y?\",\n",
    "    \"What were the main challenges in the last sprint?\",\n",
    "    \"Who should I contact about the database migration?\",\n",
    "    \"What is our current deployment process?\",\n",
    "    \"What are the known performance bottlenecks?\",\n",
    "    \"When is the next major release planned?\",\n",
    "    \"What security considerations were discussed?\",\n",
    "    \"How do we handle error monitoring?\",\n",
    "    \"What are the testing strategies in place?\",\n",
    "    \"Who are the key stakeholders for feature X?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d4027",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Memory Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize content by types for better retrieval\n",
    "content_types = {\n",
    "    \"Decision Log\": \"Important project decisions and rationale\",\n",
    "    \"Meeting Notes\": \"Meeting summaries and action items\",\n",
    "    \"Technical Doc\": \"Architecture, design, and implementation details\",\n",
    "    \"Team Update\": \"Team changes, roles, and responsibilities\", \n",
    "    \"Sprint Update\": \"Sprint goals, achievements, and blockers\",\n",
    "    \"Architecture Decision\": \"Technical architecture choices\",\n",
    "    \"Process Change\": \"Changes to development or operational processes\",\n",
    "    \"Incident Report\": \"System issues and resolutions\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ae7f9c",
   "metadata": {},
   "source": [
    "## Error Handling and Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc4ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def debug_memory_operations(self, operation: str, **kwargs):\n",
    "    \"\"\"Debug helper for memory operations\"\"\"\n",
    "    logger.info(f\"Memory operation: {operation}\")\n",
    "    logger.info(f\"Parameters: {kwargs}\")\n",
    "    \n",
    "    if self.memory is None:\n",
    "        logger.warning(\"Using fallback memory storage\")\n",
    "    else:\n",
    "        logger.info(\"Using Mem0 vector storage\")\n",
    "\n",
    "def validate_inputs(self, content: str, project_id: str, content_type: str):\n",
    "    \"\"\"Validate inputs before storing\"\"\"\n",
    "    if not content or not content.strip():\n",
    "        raise ValueError(\"Content cannot be empty\")\n",
    "    \n",
    "    if not project_id or not project_id.strip():\n",
    "        raise ValueError(\"Project ID cannot be empty\")\n",
    "    \n",
    "    if len(content) < 10:\n",
    "        logger.warning(\"Content is very short, consider adding more detail\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a061f2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "1. **Memory initialization fails**\n",
    "   ```python\n",
    "   # The system includes automatic fallback to in-memory storage\n",
    "   # Check your environment variables and API keys\n",
    "   ```\n",
    "\n",
    "2. **Poor search results**\n",
    "   ```python\n",
    "   # Use more specific search terms\n",
    "   # Include context and keywords relevant to your query\n",
    "   # Consider breaking complex questions into simpler ones\n",
    "   ```\n",
    "\n",
    "3. **Agent responses are generic**\n",
    "   ```python\n",
    "   # Store more detailed and structured project information\n",
    "   # Include specific dates, people, and technical details\n",
    "   # Use consistent terminology across your project knowledge\n",
    "   ```\n",
    "\n",
    "## Extending the System\n",
    "\n",
    "### Custom Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992fb01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_agent(self, role: str, system_prompt: str) -> ChatAgent:\n",
    "    \"\"\"Create a custom agent for specific tasks\"\"\"\n",
    "    model = ModelFactory.create(\n",
    "        model_platform=ModelPlatformType.OPENAI,\n",
    "        model_type=ModelType.GPT_4O_MINI\n",
    "    )\n",
    "    \n",
    "    return ChatAgent(\n",
    "        system_message=BaseMessage.make_assistant_message(\n",
    "            role_name=role,\n",
    "            content=system_prompt\n",
    "        ),\n",
    "        model=model\n",
    "    )\n",
    "\n",
    "# Example: Risk Assessment Agent\n",
    "risk_agent = create_custom_agent(\n",
    "    \"Risk Assessor\",\n",
    "    \"You analyze project information to identify potential risks and suggest mitigation strategies.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd154770",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Integration with External Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_with_slack(self, webhook_url: str, briefing: str):\n",
    "    \"\"\"Send briefing to Slack channel\"\"\"\n",
    "    import requests\n",
    "    \n",
    "    payload = {\n",
    "        \"text\": f\"ðŸ“‹ New Project Briefing Generated:\\n\\n{briefing}\"\n",
    "    }\n",
    "    \n",
    "    response = requests.post(webhook_url, json=payload)\n",
    "    return response.status_code == 200\n",
    "\n",
    "def export_to_markdown(self, briefing: str, filename: str):\n",
    "    \"\"\"Export briefing to markdown file\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(briefing)\n",
    "    print(f\"Briefing exported to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604e0d1",
   "metadata": {},
   "source": [
    "This cookbook provides a complete foundation for building an intelligent project briefing system using CAMEL-AI and Mem0, with robust error handling, fallback mechanisms, and extensibility options."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
