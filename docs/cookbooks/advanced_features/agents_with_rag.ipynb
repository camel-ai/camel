{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQMBlxsBv1cH"
      },
      "source": [
        "# RAG Cookbook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyl4eJue3Sm"
      },
      "source": [
        "You can also check this cookbook in colab [here](https://colab.research.google.com/drive/1U94FqDq2_yJUJW2ggD-SkyrawEvUjeXN?usp=sharing)\n",
        "\n",
        "⭐ <i>Star us on [*Github*](https://github.com/camel-ai/camel), join our [*Discord*](https://discord.camel-ai.org) or follow our [*X*](https://x.com/camelaiorg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nCRZU5sInDK"
      },
      "source": [
        "## Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwnfLQvMvtXo"
      },
      "source": [
        "In this notebook, we show the usage of CAMEL Retrieve Module in both customized way and auto way. We will also show how to combine `AutoRetriever` with `ChatAgent`, and further combine `AutoRetriever` with `RolePlaying` by using `Function Calling`.\n",
        "\n",
        "4 main parts included:\n",
        "\n",
        "- Customized RAG\n",
        "\n",
        "- Auto RAG\n",
        "\n",
        "- Single Agent with Auto RAG\n",
        "\n",
        "- Role-playing with Auto RAG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuZwbB1IIuUi"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIJK4Lu5Iwm0"
      },
      "source": [
        "Ensure you have CAMEL AI installed in your Python environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HTKnWg9Xv_y4"
      },
      "outputs": [],
      "source": [
        "!pip install \"camel-ai[all]==0.2.66\"\n",
        "!pip install \"unstructured[pdf]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUpFBEB9vrIz"
      },
      "source": [
        "## Load Data\n",
        "Let's first load the CAMEL paper from https://arxiv.org/pdf/2303.17760.pdf. This will be our local example data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dUVE7z9hwEV7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "os.makedirs('local_data', exist_ok=True)\n",
        "\n",
        "url = \"https://arxiv.org/pdf/2303.17760.pdf\"\n",
        "response = requests.get(url)\n",
        "with open('local_data/camel_paper.pdf', 'wb') as file:\n",
        "     file.write(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCqghaGiwkdv"
      },
      "source": [
        "## 1. Customized RAG\n",
        "In this section we will set our customized RAG pipeline, we will take `VectorRetriever` as an example.\n",
        "Set embedding model, we will use `OpenAIEmbedding` as the embedding model, so we need to set the `OPENAI_API_KEY` in below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxG99FkYwm_p",
        "outputId": "32a02cc7-78cd-4745-e119-41fb1e58444a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your API key: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "# Prompt for the OpenAI API key securely\n",
        "openai_api_key = getpass('Enter your API key: ')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZe0Uq-oX3PS"
      },
      "source": [
        "Alternatively, if running on Colab, you could save your API keys and tokens as **Colab Secrets**, and use them across notebooks.\n",
        "\n",
        "To do so, **comment out** the above **manual** API key prompt code block(s), and **uncomment** the following codeblock.\n",
        "\n",
        "⚠️ Don't forget granting access to the API key you would be using to the current notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xNHX9SUFX3PS"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# from google.colab import userdata\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NACsmaa0wple"
      },
      "source": [
        "Import and set the embedding instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NCT5ygT-wrku"
      },
      "outputs": [],
      "source": [
        "from camel.embeddings import OpenAIEmbedding\n",
        "from camel.types import EmbeddingModelType\n",
        "\n",
        "embedding_instance = OpenAIEmbedding(model_type=EmbeddingModelType.TEXT_EMBEDDING_3_LARGE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4nVmsm0w5lH"
      },
      "source": [
        "Import and set the vector storage instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "IQ30ih1_w6p3"
      },
      "outputs": [],
      "source": [
        "from camel.storages import QdrantStorage\n",
        "\n",
        "storage_instance = QdrantStorage(\n",
        "    vector_dim=embedding_instance.get_output_dim(),\n",
        "    path=\"local_data\",\n",
        "    collection_name=\"camel_paper\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9KccfRDw9F4"
      },
      "source": [
        "Import and set the retriever instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "d8S6VjAQHnai"
      },
      "outputs": [],
      "source": [
        "from camel.retrievers import VectorRetriever\n",
        "\n",
        "vector_retriever = VectorRetriever(embedding_model=embedding_instance,\n",
        "                                   storage=storage_instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdezllM6Hp83"
      },
      "source": [
        "We use integrated `Unstructured Module` to splite the content into small chunks, the content will be splited automacitlly with its `chunk_by_title` function, the max character for each chunk is 500 characters, which is a suitable length for `OpenAIEmbedding`. All the text in the chunks will be embed and stored to the vector storage instance, it will take some time, please wait.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QTFvD3_SHv3m"
      },
      "outputs": [],
      "source": [
        "vector_retriever.process(\n",
        "    content=\"local_data/camel_paper.pdf\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nhIo1wUHyvl"
      },
      "source": [
        "\n",
        "Now we can retrieve information from the vector storage by giving a query. By default it will give you back the text content from top 1 chunk with highest Cosine similarity score, and the similarity score should be higher than 0.75 to ensure the retrieved content is relevant to the query. You can also change the `top_k` value and `similarity_threshold` value with your needs.\n",
        "\n",
        "The returned dictionary list includes:\n",
        "- similarity score\n",
        "- content path\n",
        "- metadata\n",
        "- text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDu43Hb3GVrs",
        "outputId": "240216f4-988e-45cc-f325-54992a80ed17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'similarity score': '0.8733044970215764', 'content path': 'local_data/camel_paper.pdf', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 10, 'piece_num': 111}, 'extra_info': {}, 'text': '6 Conclusion In this paper, we explore the potential of autonomous cooperation among communicative agents and propose a novel cooperative agent framework named role-playing . Our approach enables communicative agents to collaborate autonomously toward completing tasks while requiring minimal human intervention, leading to better solutions are per our thorough evaluations. Through our analysis, we show that achieving autonomous cooperation is challenging due to issues like conversation deviation,'}]\n"
          ]
        }
      ],
      "source": [
        "retrieved_info = vector_retriever.query(\n",
        "    query=\"To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing .\",\n",
        "    top_k=1\n",
        ")\n",
        "print(retrieved_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48G3USMzH6Hd"
      },
      "source": [
        "Let's try an irrelevant query:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNh3tjCOH7d0",
        "outputId": "c043bf61-649b-4935-c7b5-9edd889caa02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'No suitable information retrieved from local_data/camel_paper.pdf with similarity_threshold = 0.5.'}]\n"
          ]
        }
      ],
      "source": [
        "retrieved_info_irrevelant = vector_retriever.query(\n",
        "    query=\"Compared with dumpling and rice, which should I take for dinner?\",\n",
        "    top_k=1,\n",
        "    similarity_threshold=0.5\n",
        ")\n",
        "\n",
        "print(retrieved_info_irrevelant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHdEsIzSH_AD"
      },
      "source": [
        "## 2. Auto RAG\n",
        "In this section we will run the `AutoRetriever` with default settings. It uses `OpenAIEmbedding` as default embedding model and `Qdrant` as default vector storage.\n",
        "\n",
        "What you need to do is:\n",
        "- Set content input paths, which can be local paths or remote urls\n",
        "- Give a query\n",
        "\n",
        "The Auto RAG pipeline would create collections for given content input paths, the collection name will be set automatically based on the content input path name, if the collection exists, it will do the retrieve directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_-zAOJ7GjVm",
        "outputId": "c93ff00d-3a59-44f7-a1ed-eb64b00845a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Original Query': \"If I'm interest in contributing to the CAMEL project, what should I do?\", 'Retrieved Context': [{'similarity score': '0.4552838106745441', 'content path': 'local_data/camel_paper.pdf', 'metadata': {'filetype': 'application/pdf', 'languages': ['eng'], 'page_number': 45, 'piece_num': 314}, 'extra_info': {}, 'text': 'CAMEL Data and Code License The intended purpose and licensing of CAMEL is solely for research use. The source code is licensed under Apache 2.0. The datasets are licensed under CC BY NC 4.0, which permits only non-commercial usage. It is advised that any models trained using the dataset should not be utilized for anything other than research purposes.\\n\\n45'}]}\n"
          ]
        }
      ],
      "source": [
        "from camel.retrievers import AutoRetriever\n",
        "from camel.types import StorageType\n",
        "\n",
        "auto_retriever = AutoRetriever(\n",
        "        vector_storage_local_path=\"local_data2/\",\n",
        "        storage_type=StorageType.QDRANT,\n",
        "        embedding_model=embedding_instance)\n",
        "\n",
        "retrieved_info = auto_retriever.run_vector_retriever(\n",
        "    query=\"If I'm interest in contributing to the CAMEL project, what should I do?\",\n",
        "    contents=[\n",
        "        \"local_data/camel_paper.pdf\",  # example local path\n",
        "        \"https://github.com/camel-ai/camel/wiki/Contributing-Guidlines\",  # example remote url\n",
        "    ],\n",
        "    top_k=1,\n",
        "    return_detailed_info=True,\n",
        "    similarity_threshold=0.4\n",
        ")\n",
        "\n",
        "print(retrieved_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMgCWKG4IQYF"
      },
      "source": [
        "## 3. Single Agent with Auto RAG\n",
        "In this section we will show how to combine the `AutoRetriever` with one `ChatAgent`.\n",
        "\n",
        "Let's set an agent function, in this function we can get the response by providing a query to this agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTE_mUwGIok-",
        "outputId": "c17c7367-b88f-4249-bbe2-87e816f7fc3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If you are interested in contributing to the CAMEL project, you should be aware that the project is intended solely for research use. The source code is licensed under Apache 2.0, and the datasets are licensed under CC BY NC 4.0, which permits only non-commercial usage. You should ensure that any contributions align with these licenses and that any models trained using the dataset are used for research purposes only. It is advisable to follow the project's guidelines and licensing terms when contributing.\n"
          ]
        }
      ],
      "source": [
        "from camel.agents import ChatAgent\n",
        "from camel.messages import BaseMessage\n",
        "from camel.types import RoleType\n",
        "from camel.retrievers import AutoRetriever\n",
        "from camel.types import StorageType\n",
        "\n",
        "def single_agent(query: str) ->str :\n",
        "    # Set agent role\n",
        "    assistant_sys_msg = \"\"\"You are a helpful assistant to answer question,\n",
        "         I will give you the Original Query and Retrieved Context,\n",
        "        answer the Original Query based on the Retrieved Context,\n",
        "        if you can't answer the question just say I don't know.\"\"\"\n",
        "\n",
        "    # Add auto retriever\n",
        "    auto_retriever = AutoRetriever(\n",
        "            vector_storage_local_path=\"local_data2/\",\n",
        "            storage_type=StorageType.QDRANT,\n",
        "            embedding_model=embedding_instance)\n",
        "\n",
        "    retrieved_info = auto_retriever.run_vector_retriever(\n",
        "        query=query,\n",
        "        contents=[\n",
        "            \"local_data/camel_paper.pdf\",  # example local path\n",
        "            \"https://github.com/camel-ai/camel/wiki/Contributing-Guidlines\",  # example remote url\n",
        "        ],\n",
        "        top_k=1,\n",
        "        return_detailed_info=False,\n",
        "        similarity_threshold=0.4\n",
        "    )\n",
        "\n",
        "    # Pass the retrieved information to agent\n",
        "    user_msg = str(retrieved_info)\n",
        "    agent = ChatAgent(assistant_sys_msg)\n",
        "\n",
        "    # Get response\n",
        "    assistant_response = agent.step(user_msg)\n",
        "    return assistant_response.msg.content\n",
        "\n",
        "print(single_agent(\"If I'm interest in contributing to the CAMEL project, what should I do?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cvh6e3KpI0rf"
      },
      "source": [
        "## 4. Role-playing with Auto RAG\n",
        "In this section we will show how to combine the `RETRIEVAL_FUNCS` with `RolePlaying` by applying `Function Calling`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "z3tX4EJVI1hb"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from colorama import Fore\n",
        "\n",
        "from camel.types.agents import ToolCallingRecord\n",
        "from camel.configs import ChatGPTConfig\n",
        "from camel.toolkits import (\n",
        "    MathToolkit,\n",
        "    RetrievalToolkit,\n",
        ")\n",
        "from camel.societies import RolePlaying\n",
        "from camel.types import ModelType, ModelPlatformType\n",
        "from camel.utils import print_text_animated\n",
        "from camel.models import ModelFactory\n",
        "\n",
        "def role_playing_with_rag(\n",
        "    task_prompt,\n",
        "    model_platform=ModelPlatformType.OPENAI,\n",
        "    model_type=ModelType.GPT_4O,\n",
        "    chat_turn_limit=5,\n",
        ") -> None:\n",
        "    task_prompt = task_prompt\n",
        "\n",
        "    tools_list = [\n",
        "        *MathToolkit().get_tools(),\n",
        "        *RetrievalToolkit().get_tools(),\n",
        "    ]\n",
        "\n",
        "\n",
        "    role_play_session = RolePlaying(\n",
        "        assistant_role_name=\"Searcher\",\n",
        "        user_role_name=\"Professor\",\n",
        "        assistant_agent_kwargs=dict(\n",
        "            model=ModelFactory.create(\n",
        "                model_platform=model_platform,\n",
        "                model_type=model_type,\n",
        "            ),\n",
        "            tools=tools_list,\n",
        "        ),\n",
        "        user_agent_kwargs=dict(\n",
        "            model=ModelFactory.create(\n",
        "                model_platform=model_platform,\n",
        "                model_type=model_type,\n",
        "            ),\n",
        "        ),\n",
        "        task_prompt=task_prompt,\n",
        "        with_task_specify=False,\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        Fore.GREEN\n",
        "        + f\"AI Assistant sys message:\\n{role_play_session.assistant_sys_msg}\\n\"\n",
        "    )\n",
        "    print(\n",
        "        Fore.BLUE + f\"AI User sys message:\\n{role_play_session.user_sys_msg}\\n\"\n",
        "    )\n",
        "\n",
        "    print(Fore.YELLOW + f\"Original task prompt:\\n{task_prompt}\\n\")\n",
        "    print(\n",
        "        Fore.CYAN\n",
        "        + \"Specified task prompt:\"\n",
        "        + f\"\\n{role_play_session.specified_task_prompt}\\n\"\n",
        "    )\n",
        "    print(Fore.RED + f\"Final task prompt:\\n{role_play_session.task_prompt}\\n\")\n",
        "\n",
        "    n = 0\n",
        "    input_msg = role_play_session.init_chat()\n",
        "    while n < chat_turn_limit:\n",
        "        n += 1\n",
        "        assistant_response, user_response = role_play_session.step(input_msg)\n",
        "\n",
        "        if assistant_response.terminated:\n",
        "            print(\n",
        "                Fore.GREEN\n",
        "                + (\n",
        "                    \"AI Assistant terminated. Reason: \"\n",
        "                    f\"{assistant_response.info['termination_reasons']}.\"\n",
        "                )\n",
        "            )\n",
        "            break\n",
        "        if user_response.terminated:\n",
        "            print(\n",
        "                Fore.GREEN\n",
        "                + (\n",
        "                    \"AI User terminated. \"\n",
        "                    f\"Reason: {user_response.info['termination_reasons']}.\"\n",
        "                )\n",
        "            )\n",
        "            break\n",
        "\n",
        "        # Print output from the user\n",
        "        print_text_animated(\n",
        "            Fore.BLUE + f\"AI User:\\n\\n{user_response.msg.content}\\n\"\n",
        "        )\n",
        "\n",
        "        # Print output from the assistant, including any function\n",
        "        # execution information\n",
        "        print_text_animated(Fore.GREEN + \"AI Assistant:\")\n",
        "        tool_calls: List[ToolCallingRecord] = [\n",
        "            ToolCallingRecord(**call.as_dict())\n",
        "            for call in assistant_response.info['tool_calls']\n",
        "        ]\n",
        "        for func_record in tool_calls:\n",
        "            print_text_animated(f\"{func_record}\")\n",
        "        print_text_animated(f\"{assistant_response.msg.content}\\n\")\n",
        "\n",
        "        if \"CAMEL_TASK_DONE\" in user_response.msg.content:\n",
        "            break\n",
        "\n",
        "        input_msg = assistant_response.msg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4-0lswwI5Gb"
      },
      "source": [
        "Run the role-playing with defined retriever function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5agjiXHeI64q",
        "outputId": "be625c0f-653a-484f-c649-c1d9ddc76c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mAI Assistant sys message:\n",
            "BaseMessage(role_name='Searcher', role_type=<RoleType.ASSISTANT: 'assistant'>, meta_dict={'task': \"If I'm interest in contributing to the CAMEL projec and I encounter some challenges during the setup process, what should I do? You should refer to the content in url https://github.com/camel-ai/camel/wiki/Contributing-Guidlines to answer my question, don't generate the answer by yourself, adjust the similarity threshold to lower value is necessary\", 'assistant_role': 'Searcher', 'user_role': 'Professor'}, content=\"===== RULES OF ASSISTANT =====\\nNever forget you are a Searcher and I am a Professor. Never flip roles! Never instruct me!\\nWe share a common interest in collaborating to successfully complete a task.\\nYou must help me to complete the task.\\nHere is the task: If I'm interest in contributing to the CAMEL projec and I encounter some challenges during the setup process, what should I do? You should refer to the content in url https://github.com/camel-ai/camel/wiki/Contributing-Guidlines to answer my question, don't generate the answer by yourself, adjust the similarity threshold to lower value is necessary. Never forget our task!\\nI must instruct you based on your expertise and my needs to complete the task.\\n\\nI must give you one instruction at a time.\\nYou must write a specific solution that appropriately solves the requested instruction and explain your solutions.\\nYou must decline my instruction honestly if you cannot perform the instruction due to physical, moral, legal reasons or your capability and explain the reasons.\\nUnless I say the task is completed, you should always start with:\\n\\nSolution: <YOUR_SOLUTION>\\n\\n<YOUR_SOLUTION> should be very specific, include detailed explanations and provide preferable detailed implementations and examples and lists for task-solving.\\nAlways end <YOUR_SOLUTION> with: Next request.\", video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)\n",
            "\n",
            "\u001b[34mAI User sys message:\n",
            "BaseMessage(role_name='Professor', role_type=<RoleType.USER: 'user'>, meta_dict={'task': \"If I'm interest in contributing to the CAMEL projec and I encounter some challenges during the setup process, what should I do? You should refer to the content in url https://github.com/camel-ai/camel/wiki/Contributing-Guidlines to answer my question, don't generate the answer by yourself, adjust the similarity threshold to lower value is necessary\", 'assistant_role': 'Searcher', 'user_role': 'Professor'}, content='===== RULES OF USER =====\\nNever forget you are a Professor and I am a Searcher. Never flip roles! You will always instruct me.\\nWe share a common interest in collaborating to successfully complete a task.\\nI must help you to complete the task.\\nHere is the task: If I\\'m interest in contributing to the CAMEL projec and I encounter some challenges during the setup process, what should I do? You should refer to the content in url https://github.com/camel-ai/camel/wiki/Contributing-Guidlines to answer my question, don\\'t generate the answer by yourself, adjust the similarity threshold to lower value is necessary. Never forget our task!\\nYou must instruct me based on my expertise and your needs to solve the task ONLY in the following two ways:\\n\\n1. Instruct with a necessary input:\\nInstruction: <YOUR_INSTRUCTION>\\nInput: <YOUR_INPUT>\\n\\n2. Instruct without any input:\\nInstruction: <YOUR_INSTRUCTION>\\nInput: None\\n\\nThe \"Instruction\" describes a task or question. The paired \"Input\" provides further context or information for the requested \"Instruction\".\\n\\nYou must give me one instruction at a time.\\nI must write a response that appropriately solves the requested instruction.\\nI must decline your instruction honestly if I cannot perform the instruction due to physical, moral, legal reasons or my capability and explain the reasons.\\nYou should instruct me not ask me questions.\\nNow you must start to instruct me using the two ways described above.\\nDo not add anything else other than your instruction and the optional corresponding input!\\nKeep giving me instructions and necessary inputs until you think the task is completed.\\nWhen the task is completed, you must only reply with a single word <CAMEL_TASK_DONE>.\\nNever say <CAMEL_TASK_DONE> unless my responses have solved your task.', video_bytes=None, image_list=None, image_detail='auto', video_detail='low', parsed=None)\n",
            "\n",
            "\u001b[33mOriginal task prompt:\n",
            "If I'm interest in contributing to the CAMEL projec and I encounter some challenges during the setup process, what should I do? You should refer to the content in url https://github.com/camel-ai/camel/wiki/Contributing-Guidlines to answer my question, don't generate the answer by yourself, adjust the similarity threshold to lower value is necessary\n",
            "\n",
            "\u001b[36mSpecified task prompt:\n",
            "None\n",
            "\n",
            "\u001b[31mFinal task prompt:\n",
            "If I'm interest in contributing to the CAMEL projec and I encounter some challenges during the setup process, what should I do? You should refer to the content in url https://github.com/camel-ai/camel/wiki/Contributing-Guidlines to answer my question, don't generate the answer by yourself, adjust the similarity threshold to lower value is necessary\n",
            "\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Access the Contributing Guidelines for the CAMEL project.  \n",
            "Input: URL - https://github.com/camel-ai/camel/wiki/Contributing-Guidlines\n",
            "\u001b[32mAI Assistant:Tool Execution: information_retrieval\n",
            "\tArgs: {'query': 'contributing guidelines CAMEL project', 'contents': 'https://github.com/camel-ai/camel/wiki/Contributing-Guidlines', 'top_k': 5, 'similarity_threshold': 0.1}\n",
            "\tResult: {'Original Query': 'contributing guidelines CAMEL project', 'Retrieved Context': ['camel-ai / camel Public\\n\\nNotifications\\n\\nFork 1.4k\\n\\nStar 13.2k']}\n",
            "Solution: The content retrieved from the provided URL seems to be insufficient to provide a detailed explanation of the Contributing Guidelines for the CAMEL project. The retrieved context only includes basic repository information, such as the number of forks and stars. It does not include the details necessary for understanding how to address challenges during the setup process or contribute effectively. \n",
            "\n",
            "I recommend trying the following steps to access the guidelines directly:\n",
            "\n",
            "1. Visit the URL: [CAMEL Contributing Guidelines](https://github.com/camel-ai/camel/wiki/Contributing-Guidlines) directly in a web browser.\n",
            "2. Review the document for setup instructions, contribution protocols, and troubleshooting guidelines.\n",
            "\n",
            "If you have specific questions or need further assistance with any part of the CAMEL project's contribution process, feel free to ask, and I can help guide you through those areas.\n",
            "\n",
            "Next request.\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Navigate to the CAMEL project's repository on GitHub and look for any \"Issues\" section.  \n",
            "Input: None\n",
            "\u001b[32mAI Assistant:Solution: To navigate to the Issues section of the CAMEL project's repository on GitHub, please follow these steps:\n",
            "\n",
            "1. Open a web browser and visit the CAMEL project's GitHub repository, which can be found at: [https://github.com/camel-ai/camel](https://github.com/camel-ai/camel)\n",
            "\n",
            "2. Once on the repository page, you'll see a navigation bar at the top. Look for the \"Issues\" tab. It is usually located between the \"Pull requests\" and \"Actions\" tabs.\n",
            "\n",
            "3. Click on the \"Issues\" tab to access the section. This is where you can view existing issues, file new issues, or find discussions related to various challenges, bugs, or feature requests related to the CAMEL project.\n",
            "\n",
            "This section can be very helpful for troubleshooting common problems, seeing if others have encountered similar issues, or finding potential solutions contributed by the community.\n",
            "\n",
            "If you need assistance with anything specific within the Issues section, feel free to ask!\n",
            "\n",
            "Next request.\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Check if there are any \"Discussions\" or \"Community\" sections in the CAMEL GitHub repository for additional insights.  \n",
            "Input: None\n",
            "\u001b[32mAI Assistant:Solution: To find the \"Discussions\" or \"Community\" sections in the CAMEL GitHub repository, follow these steps:\n",
            "\n",
            "1. Go to the CAMEL project's repository on GitHub by visiting: [https://github.com/camel-ai/camel](https://github.com/camel-ai/camel)\n",
            "\n",
            "2. On the main page of the repository, look at the navigation bar at the top of the page. \n",
            "\n",
            "3. Search for a tab labeled \"Discussions.\" This tab is often located between the \"Actions\" and \"Projects\" tabs in the navigation bar, if it is available. Clicking on this tab will take you to a section dedicated to conversations, questions, and community engagement related to the project.\n",
            "\n",
            "4. If the \"Discussions\" tab is not present, you might check the \"Community\" profile or section. This can often be found under the repository insights or on a sidebar. It provides resources for engaging with the maintainers or other users, such as contributing guidelines, a code of conduct, or links to other community platforms.\n",
            "\n",
            "These sections are very useful for engaging with other contributors, asking questions, and gaining insights into the project beyond what's presented in the code and documentation.\n",
            "\n",
            "If you find these sections and need further guidance on how to use them, feel free to ask!\n",
            "\n",
            "Next request.\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Explore the \"Wiki\" tab on the CAMEL project's GitHub repository for additional setup information or contribution guidelines.  \n",
            "Input: None\n",
            "\u001b[32mAI Assistant:Solution: To explore the \"Wiki\" tab on the CAMEL project's GitHub repository for additional setup information or contribution guidelines, please follow these steps:\n",
            "\n",
            "1. Visit the CAMEL project's GitHub repository by going to the URL: [https://github.com/camel-ai/camel](https://github.com/camel-ai/camel)\n",
            "\n",
            "2. Once you are on the repository's main page, look for the \"Wiki\" tab. This tab is usually located along the row of tabs at the top of the repository page, next to “Projects” and “Security.”\n",
            "\n",
            "3. Click on the \"Wiki\" tab to access it. The Wiki typically contains various pages created by the project maintainers and contributors that include detailed information about the project, such as setup instructions, contribution guidelines, development practices, and FAQs.\n",
            "\n",
            "4. Once in the Wiki, you can browse different pages or use the search feature to find specific information related to setup or contributing.\n",
            "\n",
            "This section is an excellent resource for thorough documentation and step-by-step guides on how to work with the project. If you encounter specific topics in the Wiki and need more details or assistance, feel free to reach out!\n",
            "\n",
            "Next request.\n",
            "\u001b[34mAI User:\n",
            "\n",
            "Instruction: Attempt to clone the CAMEL project's repository to your local machine to start the hands-on setup process.  \n",
            "Input: None\n",
            "\u001b[32mAI Assistant:Solution: To clone the CAMEL project's repository to your local machine and begin the hands-on setup process, follow these steps:\n",
            "\n",
            "1. **Prerequisites:**\n",
            "   - Ensure you have Git installed on your local machine. You can download it from [Git's official website](https://git-scm.com/) if it's not already installed.\n",
            "\n",
            "2. **Open a Terminal or Command Prompt:**\n",
            "   - On Windows, you can use Command Prompt, PowerShell, or Git Bash.\n",
            "   - On macOS or Linux, use the Terminal application.\n",
            "\n",
            "3. **Navigate to Your Desired Directory:**\n",
            "   - Use the `cd` command to change to the directory where you want to clone the repository. For example:\n",
            "     ```bash\n",
            "     cd /path/to/your/directory\n",
            "     ```\n",
            "\n",
            "4. **Clone the Repository:**\n",
            "   - Use the `git clone` command followed by the URL of the CAMEL repository:\n",
            "     ```bash\n",
            "     git clone https://github.com/camel-ai/camel.git\n",
            "     ```\n",
            "   - This command will create a directory named `camel` containing all the files from the repository.\n",
            "\n",
            "5. **Navigate into the Project Directory:**\n",
            "   - Change into the newly created directory:\n",
            "     ```bash\n",
            "     cd camel\n",
            "     ```\n",
            "\n",
            "6. **Review Setup Instructions:**\n",
            "   - After cloning the repository, it’s a good idea to check for a README file or other documentation that might include further setup steps. Often, these files guide you through installing dependencies and running the project for the first time.\n",
            "\n",
            "These steps will help you clone the repository to your local machine, and you can begin exploring the files and working on setting it up further.\n",
            "\n",
            "If you encounter any issues during this process or need more detailed instructions for specific aspects of the setup, let me know!\n",
            "\n",
            "Next request.\n"
          ]
        }
      ],
      "source": [
        "role_playing_with_rag(task_prompt = \"\"\"If I'm interest in contributing to the CAMEL projec and I encounter some challenges during the setup process, what should I do? You should refer to the content in url https://github.com/camel-ai/camel/wiki/Contributing-Guidlines to answer my question, don't generate the answer by yourself, adjust the similarity threshold to lower value is necessary\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cPSQlOlQbdGS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}