<a id="camel.models.openai_compatible_model"></a>

<a id="camel.models.openai_compatible_model.OpenAICompatibleModel"></a>

## OpenAICompatibleModel Objects

```python
class OpenAICompatibleModel(BaseModelBackend)
```

Constructor for model backend supporting OpenAI compatibility.

**Arguments**:

- `model_type` _Union[ModelType, str]_ - Model for which a backend is
  created.
- `model_config_dict` _Optional[Dict[str, Any]], optional_ - A dictionary
  that will be fed into:obj:`openai.ChatCompletion.create()`. If
  :obj:`None`, :obj:`{}` will be used. (default: :obj:`None`)
- `api_key` _str_ - The API key for authenticating with the model service.
- `url` _str_ - The url to the model service.
- `token_counter` _Optional[BaseTokenCounter], optional_ - Token counter to
  use for the model. If not provided, :obj:`OpenAITokenCounter(
  ModelType.GPT_4O_MINI)` will be used.
- `(default` - :obj:`None`)
- `timeout` _Optional[float], optional_ - The timeout value in seconds for
  API calls. If not provided, will fall back to the MODEL_TIMEOUT
  environment variable or default to 180 seconds.
- `(default` - :obj:`None`)

<a id="camel.models.openai_compatible_model.OpenAICompatibleModel.token_counter"></a>

#### token\_counter

```python
@property
def token_counter() -> BaseTokenCounter
```

Initialize the token counter for the model backend.

**Returns**:

- `OpenAITokenCounter` - The token counter following the model's
  tokenization style.

<a id="camel.models.openai_compatible_model.OpenAICompatibleModel.stream"></a>

#### stream

```python
@property
def stream() -> bool
```

Returns whether the model is in stream mode, which sends partial
results each time.

**Returns**:

- `bool` - Whether the model is in stream mode.

