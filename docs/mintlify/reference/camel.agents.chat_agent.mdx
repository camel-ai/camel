<a id="camel.agents.chat_agent"></a>

<a id="camel.agents.chat_agent.ChatAgent"></a>

## ChatAgent Objects

```python
@track_agent(name="ChatAgent")
class ChatAgent(BaseAgent)
```

Class for managing conversations of CAMEL Chat Agents.

**Arguments**:

- `system_message` _Union[BaseMessage, str], optional_ - The system message
  for the chat agent. (default: :obj:`None`)
  model (Union[BaseModelBackend, Tuple[str, str], str, ModelType,
  Tuple[ModelPlatformType, ModelType], List[BaseModelBackend],
  List[str], List[ModelType], List[Tuple[str, str]],
  List[Tuple[ModelPlatformType, ModelType]]], optional):
  The model backend(s) to use. Can be a single instance,
  a specification (string, enum, tuple), or a list of instances
  or specifications to be managed by `ModelManager`. If a list of
  specifications (not `BaseModelBackend` instances) is provided,
  they will be instantiated using `ModelFactory`. (default:
  :obj:`ModelPlatformType.DEFAULT` with `ModelType.DEFAULT`)
- `memory` _AgentMemory, optional_ - The agent memory for managing chat
  messages. If `None`, a :obj:`ChatHistoryMemory` will be used.
- `(default` - :obj:`None`)
- `message_window_size` _int, optional_ - The maximum number of previous
  messages to include in the context window. If `None`, no windowing
  is performed. (default: :obj:`None`)
- `token_limit` _int, optional_ - The maximum number of tokens in a context.
  The context will be automatically pruned to fulfill the limitation.
  If `None`, it will be set according to the backend model.
- `(default` - :obj:`None`)
- `output_language` _str, optional_ - The language to be output by the
  agent. (default: :obj:`None`)
- `tools` _Optional[List[Union[FunctionTool, Callable]]], optional_ - List
  of available :obj:`FunctionTool` or :obj:`Callable`. (default:
  :obj:`None`)
  external_tools (Optional[List[Union[FunctionTool, Callable,
  Dict[str, Any]]]], optional): List of external tools
  (:obj:`FunctionTool` or :obj:`Callable` or :obj:`Dict[str, Any]`)
  bind to one chat agent. When these tools are called, the agent will
  directly return the request instead of processing it.
- `(default` - :obj:`None`)
- `response_terminators` _List[ResponseTerminator], optional_ - List of
  :obj:`ResponseTerminator` bind to one chat agent.
- `(default` - :obj:`None`)
- `scheduling_strategy` _str_ - name of function that defines how to select
  the next model in ModelManager. (default: :str:`round_robin`)
- `single_iteration` _bool_ - Whether to let the agent perform only one
  model calling at each step. (default: :obj:`False`)
- `agent_id` _str, optional_ - The ID of the agent. If not provided, a
  random UUID will be generated. (default: :obj:`None`)
- `stop_event` _Optional[threading.Event], optional_ - Event to signal
  termination of the agent's operation. When set, the agent will
  terminate its execution. (default: :obj:`None`)

<a id="camel.agents.chat_agent.ChatAgent.reset"></a>

#### reset

```python
def reset()
```

Resets the :obj:`ChatAgent` to its initial state.

<a id="camel.agents.chat_agent.ChatAgent.system_message"></a>

#### system\_message

```python
@property
def system_message() -> Optional[BaseMessage]
```

Returns the system message for the agent.

<a id="camel.agents.chat_agent.ChatAgent.tool_dict"></a>

#### tool\_dict

```python
@property
def tool_dict() -> Dict[str, FunctionTool]
```

Returns a dictionary of internal tools.

<a id="camel.agents.chat_agent.ChatAgent.output_language"></a>

#### output\_language

```python
@property
def output_language() -> Optional[str]
```

Returns the output language for the agent.

<a id="camel.agents.chat_agent.ChatAgent.output_language"></a>

#### output\_language

```python
@output_language.setter
def output_language(value: str) -> None
```

Set the output language for the agent.

Note that this will clear the message history.

<a id="camel.agents.chat_agent.ChatAgent.add_tool"></a>

#### add\_tool

```python
def add_tool(tool: Union[FunctionTool, Callable]) -> None
```

Add a tool to the agent.

<a id="camel.agents.chat_agent.ChatAgent.add_tools"></a>

#### add\_tools

```python
def add_tools(tools: List[Union[FunctionTool, Callable]]) -> None
```

Add a list of tools to the agent.

<a id="camel.agents.chat_agent.ChatAgent.remove_tool"></a>

#### remove\_tool

```python
def remove_tool(tool_name: str) -> bool
```

Remove a tool from the agent by name.

**Arguments**:

- `tool_name` _str_ - The name of the tool to remove.
  

**Returns**:

- `bool` - Whether the tool was successfully removed.

<a id="camel.agents.chat_agent.ChatAgent.remove_tools"></a>

#### remove\_tools

```python
def remove_tools(tool_names: List[str]) -> None
```

Remove a list of tools from the agent by name.

<a id="camel.agents.chat_agent.ChatAgent.remove_external_tool"></a>

#### remove\_external\_tool

```python
def remove_external_tool(tool_name: str) -> bool
```

Remove an external tool from the agent by name.

**Arguments**:

- `tool_name` _str_ - The name of the tool to remove.
  

**Returns**:

- `bool` - Whether the tool was successfully removed.

<a id="camel.agents.chat_agent.ChatAgent.update_memory"></a>

#### update\_memory

```python
def update_memory(message: BaseMessage,
                  role: OpenAIBackendRole,
                  timestamp: Optional[float] = None) -> None
```

Updates the agent memory with a new message.

**Arguments**:

- `message` _BaseMessage_ - The new message to add to the stored
  messages.
- `role` _OpenAIBackendRole_ - The backend role type.
- `timestamp` _Optional[float], optional_ - Custom timestamp for the
  memory record. If None, current timestamp will be used.
- `(default` - :obj:`None`)

<a id="camel.agents.chat_agent.ChatAgent.load_memory"></a>

#### load\_memory

```python
def load_memory(memory: AgentMemory) -> None
```

Load the provided memory into the agent.

**Arguments**:

- `memory` _AgentMemory_ - The memory to load into the agent.
  

**Returns**:

  None

<a id="camel.agents.chat_agent.ChatAgent.load_memory_from_path"></a>

#### load\_memory\_from\_path

```python
def load_memory_from_path(path: str) -> None
```

Loads memory records from a JSON file filtered by this agent's ID.

**Arguments**:

- `path` _str_ - The file path to a JSON memory file that uses
  JsonStorage.
  

**Raises**:

- `ValueError` - If no matching records for the agent_id are found
  (optional check; commented out below).

<a id="camel.agents.chat_agent.ChatAgent.save_memory"></a>

#### save\_memory

```python
def save_memory(path: str) -> None
```

Retrieves the current conversation data from memory and writes it
into a JSON file using JsonStorage.

**Arguments**:

- `path` _str_ - Target file path to store JSON data.

<a id="camel.agents.chat_agent.ChatAgent.clear_memory"></a>

#### clear\_memory

```python
def clear_memory() -> None
```

Clear the agent's memory and reset to initial state.

**Returns**:

  None

<a id="camel.agents.chat_agent.ChatAgent.init_messages"></a>

#### init\_messages

```python
def init_messages() -> None
```

Initializes the stored messages list with the current system
message.

<a id="camel.agents.chat_agent.ChatAgent.record_message"></a>

#### record\_message

```python
def record_message(message: BaseMessage) -> None
```

Records the externally provided message into the agent memory as if
it were an answer of the :obj:`ChatAgent` from the backend. Currently,
the choice of the critic is submitted with this method.

**Arguments**:

- `message` _BaseMessage_ - An external message to be recorded in the
  memory.

<a id="camel.agents.chat_agent.ChatAgent.step"></a>

#### step

```python
def step(
        input_message: Union[BaseMessage, str],
        response_format: Optional[Type[BaseModel]] = None
) -> ChatAgentResponse
```

Executes a single step in the chat session, generating a response
to the input message.

**Arguments**:

- `input_message` _Union[BaseMessage, str]_ - The input message for the
  agent. If provided as a BaseMessage, the `role` is adjusted to
  `user` to indicate an external message.
- `response_format` _Optional[Type[BaseModel]], optional_ - A Pydantic
  model defining the expected structure of the response. Used to
  generate a structured response if provided. (default:
  :obj:`None`)
  

**Returns**:

- `ChatAgentResponse` - Contains output messages, a termination status
  flag, and session information.

<a id="camel.agents.chat_agent.ChatAgent.astep"></a>

#### astep

```python
async def astep(
        input_message: Union[BaseMessage, str],
        response_format: Optional[Type[BaseModel]] = None
) -> ChatAgentResponse
```

Performs a single step in the chat session by generating a response
to the input message. This agent step can call async function calls.

**Arguments**:

- `input_message` _Union[BaseMessage, str]_ - The input message to the
  agent. For BaseMessage input, its `role` field that specifies
  the role at backend may be either `user` or `assistant` but it
  will be set to `user` anyway since for the self agent any
  incoming message is external. For str input, the `role_name`
  would be `User`.
- `response_format` _Optional[Type[BaseModel]], optional_ - A pydantic
  model class that includes value types and field descriptions
  used to generate a structured response by LLM. This schema
  helps in defining the expected output format. (default:
  :obj:`None`)
  

**Returns**:

- `ChatAgentResponse` - A struct containing the output messages,
  a boolean indicating whether the chat session has terminated,
  and information about the chat session.

<a id="camel.agents.chat_agent.ChatAgent.get_usage_dict"></a>

#### get\_usage\_dict

```python
def get_usage_dict(output_messages: List[BaseMessage],
                   prompt_tokens: int) -> Dict[str, int]
```

Get usage dictionary when using the stream mode.

**Arguments**:

- `output_messages` _list_ - List of output messages.
- `prompt_tokens` _int_ - Number of input prompt tokens.
  

**Returns**:

- `dict` - Usage dictionary.

<a id="camel.agents.chat_agent.ChatAgent.add_model_scheduling_strategy"></a>

#### add\_model\_scheduling\_strategy

```python
def add_model_scheduling_strategy(name: str, strategy_fn: Callable)
```

Add a scheduling strategy method provided by user to ModelManger.

**Arguments**:

- `name` _str_ - The name of the strategy.
- `strategy_fn` _Callable_ - The scheduling strategy function.

<a id="camel.agents.chat_agent.ChatAgent.clone"></a>

#### clone

```python
def clone(with_memory: bool = False) -> ChatAgent
```

Creates a new instance of :obj:`ChatAgent` with the same
configuration as the current instance.

**Arguments**:

- `with_memory` _bool_ - Whether to copy the memory (conversation
  history) to the new agent. If True, the new agent will have
  the same conversation history. If False, the new agent will
  have a fresh memory with only the system message.
- `(default` - :obj:`False`)
  

**Returns**:

- `ChatAgent` - A new instance of :obj:`ChatAgent` with the same
  configuration.

<a id="camel.agents.chat_agent.ChatAgent.__repr__"></a>

#### \_\_repr\_\_

```python
def __repr__() -> str
```

Returns a string representation of the :obj:`ChatAgent`.

**Returns**:

- `str` - The string representation of the :obj:`ChatAgent`.

<a id="camel.agents.chat_agent.ChatAgent.to_mcp"></a>

#### to\_mcp

```python
def to_mcp(
        name: str = "CAMEL-ChatAgent",
        description: str = "A helpful assistant using the CAMEL AI framework.",
        dependencies: Optional[List[str]] = None,
        host: str = "localhost",
        port: int = 8000)
```

Expose this ChatAgent as an MCP server.

**Arguments**:

- `name` _str_ - Name of the MCP server.
- `(default` - :obj:`CAMEL-ChatAgent`)
- `description` _Optional[List[str]]_ - Description of the agent. If
  None, a generic description is used. (default: :obj:`A helpful
  assistant using the CAMEL AI framework.`)
- `dependencies` _Optional[List[str]]_ - Additional
  dependencies for the MCP server. (default: :obj:`None`)
- `host` _str_ - Host to bind to for HTTP transport.
- `(default` - :obj:`localhost`)
- `port` _int_ - Port to bind to for HTTP transport.
- `(default` - :obj:`8000`)
  

**Returns**:

- `FastMCP` - An MCP server instance that can be run.

