<a id="camel.datagen.cot_datagen"></a>

<a id="camel.datagen.cot_datagen.AgentResponse"></a>

## AgentResponse Objects

```python
class AgentResponse(BaseModel)
```

Model for structured agent responses.

A Pydantic model class that represents structured responses from agents,
including a similarity score that measures the quality of the response.

**Arguments**:

- `score` _float_ - A similarity score between 0 and 1 that compares the
  current answer to the correct answer. Must be within the range
  [0, 1].

<a id="camel.datagen.cot_datagen.VerificationResponse"></a>

## VerificationResponse Objects

```python
class VerificationResponse(BaseModel)
```

Model for structured verification responses.

A Pydantic model class that represents verification results from agents,
indicating whether an answer is correct or not.

**Arguments**:

- `is_correct` _bool_ - Boolean indicating if the answer is correct.

<a id="camel.datagen.cot_datagen.CoTDataGenerator"></a>

## CoTDataGenerator Objects

```python
class CoTDataGenerator()
```

Class for generating and managing data through chat agent interactions.

This module implements a sophisticated Chain of Thought data generation
system that combines several key algorithms to produce high-quality
reasoning paths. Methods implemented:

1. Monte Carlo Tree Search (MCTS)
2. Binary Search Error Detection
3. Dual-Agent Verification System
4. Solution Tree Management

**Arguments**:

- `chat_agent` _Optional[ChatAgent]_ - Optional single agent
  for both tasks (legacy mode). (default::obj:`None`)
- `generator_agent` _Optional[ChatAgent]_ - Optional specialized agent for
  answer generation. (default::obj:`None`)
- `verifier_agent` _Optional[ChatAgent]_ - Optional specialized agent for
  answer verification. (default::obj:`None`)
- `golden_answers` _Dict[str, str]_ - Dictionary containing pre-defined
  correct answers for validation and comparison. Required for answer
  verification.
- `search_limit` _int_ - Maximum number of search iterations allowed.
  (default::obj:`100`)

<a id="camel.datagen.cot_datagen.CoTDataGenerator.__init__"></a>

#### \_\_init\_\_

```python
def __init__(chat_agent: Optional[ChatAgent] = None,
             *,
             generator_agent: Optional[ChatAgent] = None,
             verifier_agent: Optional[ChatAgent] = None,
             golden_answers: Dict[str, str],
             search_limit: int = 100)
```

Initialize the CoTDataGenerator.

This constructor supports both single-agent and dual-agent modes:
1. Single-agent mode (legacy): Pass a single chat_agent that will be
used for both generation and verification.
2. Dual-agent mode: Pass separate generator_agent and verifier_agent
for specialized tasks.

**Arguments**:

- `chat_agent` _Optional[ChatAgent]_ - Optional single agent for both
  tasks (legacy mode). (default::obj:`None`)
- `generator_agent` _Optional[ChatAgent]_ - Optional specialized agent
  for answer generation. (default::obj:`None`)
- `verifier_agent` _Optional[ChatAgent]_ - Optional specialized agent
  for answer verification. (default::obj:`None`)
- `golden_answers` _Dict[str, str]_ - Dictionary containing pre-defined
  correct answers for validation and comparison. Required for
  answer verification.
- `search_limit` _int_ - Maximum number of search iterations allowed.
  (default::obj:`100`)

<a id="camel.datagen.cot_datagen.CoTDataGenerator.get_answer"></a>

#### get\_answer

```python
def get_answer(question: str, context: str = "") -> str
```

Get an answer from the chat agent for a given question.

**Arguments**:

- `question` _str_ - The question to ask.
- `context` _str_ - Additional context for the question.
  (default::obj:`""`)
  

**Returns**:

- `str` - The generated answer.

<a id="camel.datagen.cot_datagen.CoTDataGenerator.verify_answer"></a>

#### verify\_answer

```python
def verify_answer(question: str, answer: str) -> bool
```

Verify if a generated answer is semantically equivalent to
the golden answer for a given question.

**Arguments**:

- `question` _str_ - The question being answered.
- `answer` _str_ - The answer to verify.
  

**Returns**:

- `bool` - True if the answer matches the golden answer based on
  semantic equivalence (meaning the core content and meaning are
  the same, even if the exact wording differs).
  False in the following cases:
  - If the provided question doesn't exist in the golden answers
  - If the answer's meaning differs from the golden answer

<a id="camel.datagen.cot_datagen.CoTDataGenerator.evaluate_partial_solution"></a>

#### evaluate\_partial\_solution

```python
def evaluate_partial_solution(question: str,
                              partial_solution: str = "") -> float
```

Evaluate the quality of a partial solution against the
golden answer.

This function generates a similarity score between the given partial
solution and the correct answer (golden answer).

**Arguments**:

- `question` _str_ - The question being solved.
- `partial_solution` _str_ - The partial solution generated so far.
  (default::obj:`""`)
  

**Returns**:

- `float` - A similarity score between 0 and 1, indicating how close the
  partial solution is to the golden answer.

<a id="camel.datagen.cot_datagen.CoTDataGenerator.binary_search_error"></a>

#### binary\_search\_error

```python
def binary_search_error(question: str, solution: str) -> int
```

Use binary search to locate the first error in the solution.
This method splits the solution into sentences using both English and
Chinese sentence delimiters and performs binary search to find the
first error.

**Arguments**:

- `question` _str_ - The question being solved.
- `solution` _str_ - The complete solution to analyze.
  

**Returns**:

- `int` - The position of the first error found in the solution.
  Returns -1. If no errors are found (all sentences are correct).

<a id="camel.datagen.cot_datagen.CoTDataGenerator.solve"></a>

#### solve

```python
def solve(question: str) -> str
```

Solve a question using a multi-step approach.

The solution process follows these steps:
1. Try to solve directly - if correct, return the solution.
2. If not correct, perform a search by iteratively generating
new solutions and evaluating their similarity scores to
find a good solution. The search process involves:
a. Generation: Generate new solution candidates using
the generator agent.
b. Evaluation: Score each solution candidate for similarity
to the golden answer.
c. Selection: Keep the best-scoring candidate found so far.
d. Early stopping: If a sufficiently high-scoring solution
is found (score > 0.9), stop early.
3. If the solution isn't perfect, use binary search to locate
errors.
4. Generate a new solution based on the correct part of the
initial solution.

**Arguments**:

- `question` _str_ - The question to solve.
  

**Returns**:

- `str` - The best solution found.

<a id="camel.datagen.cot_datagen.CoTDataGenerator.import_qa_from_json"></a>

#### import\_qa\_from\_json

```python
def import_qa_from_json(data: Union[str, Dict[str, str]]) -> bool
```

Import question and answer data from either a JSON file or a
dictionary.

**Arguments**:

- `data` _Union[str, Dict[str, str]]_ - Either a path to a JSON file
  containing QA pairs or a dictionary of question-answer pairs.
  If a string is provided, it's treated as a file path.
  The expected format is:
- `{"question1"` - "answer1",
- `"question2"` - "answer2",
  ...}
  

**Returns**:

- `bool` - True if import was successful, False otherwise.

<a id="camel.datagen.cot_datagen.CoTDataGenerator.export_solutions"></a>

#### export\_solutions

```python
def export_solutions(filepath: str = 'solutions.json') -> None
```

Export the solution process and results to a JSON file.
Exports the solution tree, golden answers,
and export timestamp to a JSON file.
The exported data includes:
- solutions: The solution tree
with intermediate steps
- golden_answers: The reference answers used for verification
- export_time: ISO format timestamp of the export

**Arguments**:

- `filepath` _str, optional_ - Path where the JSON file will be saved.
  (default::obj:`'solutions.json'`)
  

**Returns**:

- `None` - The method writes to a file and logs the result but does not
  return any value.

