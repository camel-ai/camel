<a id="camel.configs.watsonx_config"></a>

<a id="camel.configs.watsonx_config.WatsonXConfig"></a>

## WatsonXConfig Objects

```python
class WatsonXConfig(BaseConfig)
```

Defines the parameters for generating chat completions using the
IBM WatsonX API.

See: https://ibm.github.io/watsonx-ai-python-sdk/fm_schema.html

**Arguments**:

- `frequency_penalty` _float, optional_ - Number between -2.0 and 2.0.
  Positive values penalize new tokens based on their existing
  frequency in the text so far, decreasing the model's likelihood
  to repeat the same line verbatim.
- `(default` - :obj:`None`)
- `logprobs` _bool, optional_ - Whether to return log probabilities of the
  output tokens or not. If true, returns the log probabilities of
  each output token returned in the content of message.
- `(default` - :obj:`None`)
- `top_logprobs` _int, optional_ - An integer between 0 and 20 specifying
  the number of most likely tokens to return at each token position,
  each with an associated log probability.
- `(default` - :obj:`None`)
- `presence_penalty` _float, optional_ - Number between -2.0 and 2.0.
  Positive values penalize new tokens based on whether they appear
  in the text so far, increasing the model's likelihood to talk
  about new topics.
- `(default` - :obj:`None`)
- `temperature` _float, optional_ - What sampling temperature to use,
  between 0 and 2. Higher values like 0.8 will make the output
  more random, while lower values like 0.2 will make it more focused
  and deterministic. We generally recommend altering this or top_p
  but not both.
- `(default` - :obj:`None`)
- `max_tokens` _int, optional_ - The maximum number of tokens to generate
  in the chat completion. The total length of input tokens and
  generated tokens is limited by the model's context length.
- `(default` - :obj:`None`)
- `time_limit` _int, optional_ - The maximum amount of time in seconds
  that the API will spend generating a response.
- `(default` - :obj:`None`)
- `top_p` _float, optional_ - Controls the randomness of the generated
  results. Lower values lead to less randomness, while higher
  values increase randomness. (default: :obj:`None`)
- `n` _int, optional_ - How many chat completion choices to generate for
  each input message. Note that you will be charged based on the
  total number of tokens generated.
- `(default` - :obj:`None`)
- `logit_biaslogit_bias` _Optional[dict], optional_ - Modify probability
  of specific tokens appearing in the completion.
- `(default` - :obj:`None`)
- `seed` _int, optional_ - If specified, the system will make a best effort
  to sample deterministically, such that repeated requests with the
  same seed and parameters should return the same result.
- `(default` - :obj:`None`)
- `stop` _List[str], optional_ - Up to 4 sequences where the API will stop
  generating further tokens.
- `(default` - :obj:`None`)
- `tool_choice_options` _Literal["none", "auto"], optional_ - The options
  for the tool choice.
- `(default` - :obj:`"auto"`)

