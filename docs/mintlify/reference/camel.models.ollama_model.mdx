<a id="camel.models.ollama_model"></a>

<a id="camel.models.ollama_model.OllamaModel"></a>

## OllamaModel

```python
class OllamaModel(OpenAICompatibleModel):
```

Ollama service interface.

**Parameters:**

- **model_type** (Union[ModelType, str]): Model for which a backend is created.
- **model_config_dict** (Optional[Dict[str, Any]], optional): A dictionary that will be fed into:obj:`openai.ChatCompletion.create()`.
- **If**: obj:`None`, :obj:`OllamaConfig().as_dict()` will be used. (default: :obj:`None`)
- **api_key** (Optional[str], optional): The API key for authenticating with the model service. Ollama doesn't need API key, it would be ignored if set. (default: :obj:`None`)
- **url** (Optional[str], optional): The url to the model service. (default: :obj:`None`)
- **token_counter** (Optional[BaseTokenCounter], optional): Token counter to use for the model. If not provided, :obj:`OpenAITokenCounter( ModelType.GPT_4O_MINI)` will be used. (default: :obj:`None`)
- **timeout** (Optional[float], optional): The timeout value in seconds for API calls. If not provided, will fall back to the MODEL_TIMEOUT environment variable or default to 180 seconds. (default: :obj:`None`)
- **References**: 
- **https**: //github.com/ollama/ollama/blob/main/docs/openai.md

<a id="camel.models.ollama_model.OllamaModel.__init__"></a>

### __init__

```python
def __init__(
    self,
    model_type: Union[ModelType, str],
    model_config_dict: Optional[Dict[str, Any]] = None,
    api_key: Optional[str] = None,
    url: Optional[str] = None,
    token_counter: Optional[BaseTokenCounter] = None,
    timeout: Optional[float] = None
):
```

<a id="camel.models.ollama_model.OllamaModel._start_server"></a>

### _start_server

```python
def _start_server(self):
```

Starts the Ollama server in a subprocess.

<a id="camel.models.ollama_model.OllamaModel.check_model_config"></a>

### check_model_config

```python
def check_model_config(self):
```
